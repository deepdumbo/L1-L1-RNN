iter 50, train_loss 1494.5379638671875
eval_loss: 1494.4476318359375 psnr: 16.412372589111328
iter 100, train_loss 1380.78955078125
eval_loss: 1420.3651123046875 psnr: 16.63935089111328
iter 150, train_loss 1367.306884765625
eval_loss: 1382.8067626953125 psnr: 16.75688362121582
iter 200, train_loss 1258.1497802734375
eval_loss: 1345.086181640625 psnr: 16.877756118774414
iter 250, train_loss 1370.0162353515625
eval_loss: 1302.9346923828125 psnr: 17.016935348510742
iter 300, train_loss 1362.2923583984375
eval_loss: 1260.0855712890625 psnr: 17.163875579833984
iter 350, train_loss 1176.1458740234375
eval_loss: 1214.2552490234375 psnr: 17.32421112060547
iter 400, train_loss 1297.226318359375
eval_loss: 1169.1419677734375 psnr: 17.491230010986328
iter 450, train_loss 1195.05126953125
eval_loss: 1123.9508056640625 psnr: 17.661706924438477
iter 500, train_loss 1167.30419921875
eval_loss: 1082.094970703125 psnr: 17.83088493347168
iter 550, train_loss 1047.5609130859375
eval_loss: 1043.75341796875 psnr: 17.986181259155273
iter 600, train_loss 1266.240966796875
eval_loss: 1006.6785278320312 psnr: 18.144838333129883
iter 650, train_loss 977.8463134765625
eval_loss: 973.364501953125 psnr: 18.292783737182617
iter 700, train_loss 977.3020629882812
eval_loss: 957.9501953125 psnr: 18.363683700561523
iter 750, train_loss 963.5272827148438
eval_loss: 923.939208984375 psnr: 18.523656845092773
iter 800, train_loss 847.6002197265625
eval_loss: 898.745849609375 psnr: 18.6461181640625
iter 850, train_loss 917.20849609375
eval_loss: 876.8583374023438 psnr: 18.755813598632812
iter 900, train_loss 811.1471557617188
eval_loss: 857.0890502929688 psnr: 18.857484817504883
iter 950, train_loss 873.0947265625
eval_loss: 839.4749755859375 psnr: 18.951051712036133
iter 1000, train_loss 835.5390625
eval_loss: 823.3758544921875 psnr: 19.037662506103516
iter 1050, train_loss 922.50341796875
eval_loss: 809.1578369140625 psnr: 19.115568161010742
iter 1100, train_loss 806.1915893554688
eval_loss: 795.6973266601562 psnr: 19.192249298095703
iter 1150, train_loss 788.5453491210938
eval_loss: 783.5762939453125 psnr: 19.2618465423584
iter 1200, train_loss 752.6358032226562
eval_loss: 772.2230224609375 psnr: 19.327293395996094
iter 1250, train_loss 782.1173095703125
eval_loss: 761.2510375976562 psnr: 19.392635345458984
iter 1300, train_loss 711.2455444335938
eval_loss: 751.027587890625 psnr: 19.4526309967041
iter 1350, train_loss 814.7753295898438
eval_loss: 741.4501342773438 psnr: 19.50940704345703
iter 1400, train_loss 727.388916015625
eval_loss: 732.3598022460938 psnr: 19.565269470214844
iter 1450, train_loss 709.4590454101562
eval_loss: 723.3087158203125 psnr: 19.621320724487305
iter 1500, train_loss 686.516357421875
eval_loss: 715.176025390625 psnr: 19.672861099243164
iter 1550, train_loss 722.5050048828125
eval_loss: 707.2601318359375 psnr: 19.722963333129883
iter 1600, train_loss 678.6220092773438
eval_loss: 699.6570434570312 psnr: 19.77187728881836
iter 1650, train_loss 717.9982299804688
eval_loss: 692.2874145507812 psnr: 19.817087173461914
iter 1700, train_loss 667.9620971679688
eval_loss: 685.3900756835938 psnr: 19.86151695251465
iter 1750, train_loss 674.40869140625
eval_loss: 678.7129516601562 psnr: 19.905981063842773
iter 1800, train_loss 648.6055908203125
eval_loss: 672.5526733398438 psnr: 19.946468353271484
iter 1850, train_loss 681.5640258789062
eval_loss: 666.6060791015625 psnr: 19.98654556274414
iter 1900, train_loss 665.13232421875
eval_loss: 661.1162719726562 psnr: 20.024398803710938
iter 1950, train_loss 672.6130981445312
eval_loss: 655.7560424804688 psnr: 20.06165313720703
iter 2000, train_loss 697.1337890625
eval_loss: 650.3623046875 psnr: 20.098918914794922
iter 2050, train_loss 552.2210083007812
eval_loss: 645.250244140625 psnr: 20.131567001342773
iter 2100, train_loss 602.9741821289062
eval_loss: 640.2864379882812 psnr: 20.16558265686035
iter 2150, train_loss 668.81689453125
eval_loss: 635.3209838867188 psnr: 20.200843811035156
iter 2200, train_loss 592.4507446289062
eval_loss: 630.3328247070312 psnr: 20.23453140258789
iter 2250, train_loss 639.6400756835938
eval_loss: 625.8734741210938 psnr: 20.26778793334961
iter 2300, train_loss 535.9839477539062
eval_loss: 621.2686157226562 psnr: 20.30122184753418
iter 2350, train_loss 600.0272827148438
eval_loss: 617.131103515625 psnr: 20.332225799560547
iter 2400, train_loss 609.2548828125
eval_loss: 612.7230834960938 psnr: 20.36272621154785
iter 2450, train_loss 645.6080322265625
eval_loss: 608.8733520507812 psnr: 20.392162322998047
iter 2500, train_loss 572.0462036132812
eval_loss: 604.5070190429688 psnr: 20.420995712280273
iter 2550, train_loss 617.1207275390625
eval_loss: 600.6952514648438 psnr: 20.45099639892578
iter 2600, train_loss 621.1295776367188
eval_loss: 596.93896484375 psnr: 20.479873657226562
iter 2650, train_loss 638.554443359375
eval_loss: 592.7998657226562 psnr: 20.50992774963379
iter 2700, train_loss 548.0726318359375
eval_loss: 589.0671997070312 psnr: 20.538116455078125
iter 2750, train_loss 576.1826782226562
eval_loss: 584.9991455078125 psnr: 20.568275451660156
iter 2800, train_loss 584.3822631835938
eval_loss: 581.1798095703125 psnr: 20.59710121154785
iter 2850, train_loss 571.3690795898438
eval_loss: 577.2444458007812 psnr: 20.627229690551758
iter 2900, train_loss 590.2423095703125
eval_loss: 573.4821166992188 psnr: 20.658935546875
iter 2950, train_loss 536.0758056640625
eval_loss: 569.7385864257812 psnr: 20.68868637084961
iter 3000, train_loss 564.7001953125
eval_loss: 565.852294921875 psnr: 20.71759605407715
iter 3050, train_loss 544.51123046875
eval_loss: 562.2858276367188 psnr: 20.746456146240234
iter 3100, train_loss 542.9513549804688
eval_loss: 558.6783447265625 psnr: 20.774744033813477
iter 3150, train_loss 522.6011962890625
eval_loss: 555.4324951171875 psnr: 20.805339813232422
iter 3200, train_loss 601.26220703125
eval_loss: 552.0421752929688 psnr: 20.831541061401367
iter 3250, train_loss 547.9166870117188
eval_loss: 548.3812866210938 psnr: 20.861154556274414
iter 3300, train_loss 532.5697631835938
eval_loss: 544.8890380859375 psnr: 20.890478134155273
iter 3350, train_loss 546.4883422851562
eval_loss: 541.9702758789062 psnr: 20.914379119873047
iter 3400, train_loss 515.4605712890625
eval_loss: 538.1116333007812 psnr: 20.949806213378906
iter 3450, train_loss 526.2003173828125
eval_loss: 534.150146484375 psnr: 20.98235511779785
iter 3500, train_loss 517.4094848632812
eval_loss: 530.7177734375 psnr: 21.016246795654297
iter 3550, train_loss 529.4183349609375
eval_loss: 526.1856079101562 psnr: 21.0498104095459
iter 3600, train_loss 563.4684448242188
eval_loss: 521.614013671875 psnr: 21.088146209716797
iter 3650, train_loss 518.219970703125
eval_loss: 516.8779907226562 psnr: 21.13072395324707
iter 3700, train_loss 518.6190795898438
eval_loss: 511.8037414550781 psnr: 21.17601203918457
iter 3750, train_loss 529.9791259765625
eval_loss: 506.69427490234375 psnr: 21.222991943359375
iter 3800, train_loss 484.47705078125
eval_loss: 501.3995666503906 psnr: 21.268484115600586
iter 3850, train_loss 511.166015625
eval_loss: 496.2444763183594 psnr: 21.316015243530273
iter 3900, train_loss 472.0224609375
eval_loss: 490.7001953125 psnr: 21.371780395507812
iter 3950, train_loss 477.40924072265625
eval_loss: 485.5449523925781 psnr: 21.418292999267578
iter 4000, train_loss 441.8307800292969
eval_loss: 480.0931091308594 psnr: 21.468664169311523
iter 4050, train_loss 465.47607421875
eval_loss: 474.54833984375 psnr: 21.52250099182129
iter 4100, train_loss 490.896728515625
eval_loss: 469.31756591796875 psnr: 21.568885803222656
iter 4150, train_loss 450.031982421875
eval_loss: 464.1217346191406 psnr: 21.629587173461914
iter 4200, train_loss 447.8330078125
eval_loss: 458.7964172363281 psnr: 21.680274963378906
iter 4250, train_loss 462.201416015625
eval_loss: 453.37738037109375 psnr: 21.73369789123535
iter 4300, train_loss 465.748779296875
eval_loss: 448.55108642578125 psnr: 21.78683853149414
iter 4350, train_loss 453.0467834472656
eval_loss: 443.42083740234375 psnr: 21.83641815185547
iter 4400, train_loss 454.3312683105469
eval_loss: 439.00439453125 psnr: 21.882261276245117
iter 4450, train_loss 438.9972229003906
eval_loss: 433.9371032714844 psnr: 21.941478729248047
iter 4500, train_loss 439.3371276855469
eval_loss: 428.9612121582031 psnr: 21.997114181518555
iter 4550, train_loss 416.92755126953125
eval_loss: 424.2437438964844 psnr: 22.04006576538086
iter 4600, train_loss 424.46466064453125
eval_loss: 419.7120361328125 psnr: 22.09843635559082
iter 4650, train_loss 465.03643798828125
eval_loss: 414.9311828613281 psnr: 22.144914627075195
iter 4700, train_loss 415.2821960449219
eval_loss: 410.20147705078125 psnr: 22.204776763916016
iter 4750, train_loss 435.3352966308594
eval_loss: 405.4024353027344 psnr: 22.256568908691406
iter 4800, train_loss 404.52301025390625
eval_loss: 401.2835998535156 psnr: 22.311418533325195
iter 4850, train_loss 370.9997253417969
eval_loss: 396.64593505859375 psnr: 22.352128982543945
iter 4900, train_loss 407.6342468261719
eval_loss: 391.5921325683594 psnr: 22.41472816467285
iter 4950, train_loss 393.4600524902344
eval_loss: 387.7296447753906 psnr: 22.463287353515625
iter 5000, train_loss 337.3670959472656
eval_loss: 382.8600158691406 psnr: 22.51043128967285
iter 5050, train_loss 345.2878723144531
eval_loss: 378.0973815917969 psnr: 22.574398040771484
iter 5100, train_loss 396.57354736328125
eval_loss: 373.7156066894531 psnr: 22.628482818603516
iter 5150, train_loss 368.94500732421875
eval_loss: 369.30194091796875 psnr: 22.68016815185547
iter 5200, train_loss 337.16583251953125
eval_loss: 365.1913757324219 psnr: 22.73651885986328
iter 5250, train_loss 344.3407897949219
eval_loss: 360.9636535644531 psnr: 22.800865173339844
iter 5300, train_loss 332.4106140136719
eval_loss: 355.9399719238281 psnr: 22.863203048706055
iter 5350, train_loss 350.762451171875
eval_loss: 351.94390869140625 psnr: 22.913433074951172
iter 5400, train_loss 326.5962219238281
eval_loss: 347.6756896972656 psnr: 22.958553314208984
iter 5450, train_loss 354.1758728027344
eval_loss: 343.2083740234375 psnr: 23.022754669189453
iter 5500, train_loss 320.1870422363281
eval_loss: 338.9610290527344 psnr: 23.078027725219727
iter 5550, train_loss 368.7297058105469
eval_loss: 334.6640625 psnr: 23.131059646606445
iter 5600, train_loss 305.791259765625
eval_loss: 330.89556884765625 psnr: 23.200151443481445
iter 5650, train_loss 323.8524169921875
eval_loss: 326.5714111328125 psnr: 23.248838424682617
iter 5700, train_loss 361.9740295410156
eval_loss: 322.2730407714844 psnr: 23.318164825439453
iter 5750, train_loss 314.0534973144531
eval_loss: 318.4132995605469 psnr: 23.364805221557617
iter 5800, train_loss 305.7746276855469
eval_loss: 314.70599365234375 psnr: 23.436084747314453
iter 5850, train_loss 308.2026062011719
eval_loss: 309.5469970703125 psnr: 23.50921058654785
iter 5900, train_loss 290.0326843261719
eval_loss: 305.8778381347656 psnr: 23.559371948242188
iter 5950, train_loss 309.4191589355469
eval_loss: 302.15606689453125 psnr: 23.61393165588379
iter 6000, train_loss 286.4207458496094
eval_loss: 297.46270751953125 psnr: 23.68589210510254
iter 6050, train_loss 260.8450012207031
eval_loss: 293.7806091308594 psnr: 23.757246017456055
iter 6100, train_loss 303.4114685058594
eval_loss: 289.97283935546875 psnr: 23.801671981811523
iter 6150, train_loss 279.4855041503906
eval_loss: 286.4098205566406 psnr: 23.852977752685547
iter 6200, train_loss 280.25421142578125
eval_loss: 282.204833984375 psnr: 23.918981552124023
iter 6250, train_loss 294.4105529785156
eval_loss: 278.5249328613281 psnr: 24.001245498657227
iter 6300, train_loss 229.254150390625
eval_loss: 275.0818176269531 psnr: 24.059494018554688
iter 6350, train_loss 296.2211608886719
eval_loss: 271.6644592285156 psnr: 24.11574363708496
iter 6400, train_loss 231.76609802246094
eval_loss: 267.1994323730469 psnr: 24.192197799682617
iter 6450, train_loss 254.99302673339844
eval_loss: 264.550048828125 psnr: 24.255769729614258
iter 6500, train_loss 280.86322021484375
eval_loss: 260.3226013183594 psnr: 24.304893493652344
iter 6550, train_loss 251.9174041748047
eval_loss: 256.7150573730469 psnr: 24.374271392822266
iter 6600, train_loss 257.52032470703125
eval_loss: 253.6439971923828 psnr: 24.43254280090332
iter 6650, train_loss 257.1121520996094
eval_loss: 250.20704650878906 psnr: 24.495033264160156
iter 6700, train_loss 249.594482421875
eval_loss: 247.10348510742188 psnr: 24.567096710205078
iter 6750, train_loss 240.5452423095703
eval_loss: 244.02447509765625 psnr: 24.6252498626709
iter 6800, train_loss 231.04051208496094
eval_loss: 240.61990356445312 psnr: 24.683778762817383
iter 6850, train_loss 234.1591796875
eval_loss: 237.77444458007812 psnr: 24.75282096862793
iter 6900, train_loss 216.42930603027344
eval_loss: 234.22459411621094 psnr: 24.807483673095703
iter 6950, train_loss 232.74131774902344
eval_loss: 231.8032684326172 psnr: 24.8734188079834
iter 7000, train_loss 206.7470703125
eval_loss: 229.0777130126953 psnr: 24.921764373779297
iter 7050, train_loss 247.2223358154297
eval_loss: 226.15858459472656 psnr: 24.984779357910156
iter 7100, train_loss 235.4755401611328
eval_loss: 224.16114807128906 psnr: 25.05272102355957
iter 7150, train_loss 205.2744140625
eval_loss: 220.8487091064453 psnr: 25.086984634399414
iter 7200, train_loss 213.8376922607422
eval_loss: 219.42062377929688 psnr: 25.153766632080078
iter 7250, train_loss 198.9363555908203
eval_loss: 216.5889892578125 psnr: 25.219240188598633
iter 7300, train_loss 195.3337860107422
eval_loss: 213.97203063964844 psnr: 25.255958557128906
iter 7350, train_loss 203.44000244140625
eval_loss: 211.7020721435547 psnr: 25.30093765258789
iter 7400, train_loss 219.3091278076172
eval_loss: 209.6609649658203 psnr: 25.352487564086914
iter 7450, train_loss 203.04466247558594
eval_loss: 207.345947265625 psnr: 25.412601470947266
iter 7500, train_loss 213.51438903808594
eval_loss: 205.83456420898438 psnr: 25.443273544311523
iter 7550, train_loss 208.4766082763672
eval_loss: 203.3054656982422 psnr: 25.515779495239258
iter 7600, train_loss 171.48924255371094
eval_loss: 201.79531860351562 psnr: 25.552186965942383
iter 7650, train_loss 207.3837432861328
eval_loss: 200.49179077148438 psnr: 25.597360610961914
iter 7700, train_loss 195.5388641357422
eval_loss: 198.2292938232422 psnr: 25.642635345458984
iter 7750, train_loss 208.6646270751953
eval_loss: 196.66786193847656 psnr: 25.673892974853516
iter 7800, train_loss 199.8656768798828
eval_loss: 195.1701202392578 psnr: 25.726913452148438
iter 7850, train_loss 191.88536071777344
eval_loss: 193.6881866455078 psnr: 25.725521087646484
iter 7900, train_loss 187.3590087890625
eval_loss: 192.94046020507812 psnr: 25.79909896850586
iter 7950, train_loss 187.65696716308594
eval_loss: 191.38037109375 psnr: 25.78236961364746
iter 8000, train_loss 188.36056518554688
eval_loss: 189.8081817626953 psnr: 25.844070434570312
iter 8050, train_loss 183.56790161132812
eval_loss: 187.52450561523438 psnr: 25.90880012512207
iter 8100, train_loss 214.20703125
eval_loss: 185.74273681640625 psnr: 25.94998550415039
iter 8150, train_loss 193.70455932617188
eval_loss: 184.8321990966797 psnr: 25.968379974365234
iter 8200, train_loss 169.07223510742188
eval_loss: 183.4172821044922 psnr: 26.005720138549805
iter 8250, train_loss 179.9497833251953
eval_loss: 180.96046447753906 psnr: 26.03407859802246
iter 8300, train_loss 192.5614013671875
eval_loss: 181.1414337158203 psnr: 26.0462703704834
iter 8350, train_loss 191.84730529785156
eval_loss: 179.90353393554688 psnr: 26.10166358947754
iter 8400, train_loss 164.6314239501953
eval_loss: 177.83384704589844 psnr: 26.140663146972656
iter 8450, train_loss 182.20603942871094
eval_loss: 175.70094299316406 psnr: 26.202434539794922
iter 8500, train_loss 170.41636657714844
eval_loss: 174.99249267578125 psnr: 26.21965789794922
iter 8550, train_loss 173.24327087402344
eval_loss: 172.9300994873047 psnr: 26.269014358520508
iter 8600, train_loss 174.73631286621094
eval_loss: 171.4070281982422 psnr: 26.329696655273438
iter 8650, train_loss 175.00204467773438
eval_loss: 169.84695434570312 psnr: 26.340917587280273
iter 8700, train_loss 180.4756622314453
eval_loss: 167.89927673339844 psnr: 26.38709831237793
iter 8750, train_loss 163.645751953125
eval_loss: 166.66986083984375 psnr: 26.413930892944336
iter 8800, train_loss 175.40882873535156
eval_loss: 165.35646057128906 psnr: 26.448823928833008
iter 8850, train_loss 147.60987854003906
eval_loss: 163.25851440429688 psnr: 26.505229949951172
iter 8900, train_loss 131.3352508544922
eval_loss: 162.38536071777344 psnr: 26.53361701965332
iter 8950, train_loss 145.64146423339844
eval_loss: 160.7618865966797 psnr: 26.57756233215332
iter 9000, train_loss 144.6179962158203
eval_loss: 160.08872985839844 psnr: 26.623779296875
iter 9050, train_loss 157.51011657714844
eval_loss: 158.8358154296875 psnr: 26.65009117126465
iter 9100, train_loss 171.64915466308594
eval_loss: 157.55223083496094 psnr: 26.65791130065918
iter 9150, train_loss 141.52049255371094
eval_loss: 155.02745056152344 psnr: 26.7613525390625
iter 9200, train_loss 153.1971893310547
eval_loss: 155.0814971923828 psnr: 26.75510597229004
iter 9250, train_loss 147.0792694091797
eval_loss: 153.24713134765625 psnr: 26.819528579711914
iter 9300, train_loss 157.8726806640625
eval_loss: 151.78038024902344 psnr: 26.829221725463867
iter 9350, train_loss 136.2238006591797
eval_loss: 153.80206298828125 psnr: 26.787633895874023
iter 9400, train_loss 160.6311492919922
eval_loss: 149.50563049316406 psnr: 26.932605743408203
iter 9450, train_loss 152.2976531982422
eval_loss: 147.75875854492188 psnr: 26.93563461303711
iter 9500, train_loss 149.5064239501953
eval_loss: 146.70584106445312 psnr: 26.99435043334961
iter 9550, train_loss 148.52452087402344
eval_loss: 146.36709594726562 psnr: 27.00423240661621
iter 9600, train_loss 135.552734375
eval_loss: 145.77581787109375 psnr: 27.041521072387695
iter 9650, train_loss 143.69491577148438
eval_loss: 143.34193420410156 psnr: 27.10797882080078
iter 9700, train_loss 145.4513397216797
eval_loss: 142.22300720214844 psnr: 27.14145278930664
iter 9750, train_loss 138.0234832763672
eval_loss: 142.36502075195312 psnr: 27.15907859802246
iter 9800, train_loss 134.7577362060547
eval_loss: 139.658935546875 psnr: 27.253087997436523
iter 9850, train_loss 130.31158447265625
eval_loss: 138.37112426757812 psnr: 27.28318214416504
iter 9900, train_loss 136.3164825439453
eval_loss: 137.5218963623047 psnr: 27.287424087524414
iter 9950, train_loss 119.35870361328125
eval_loss: 137.38038635253906 psnr: 27.315685272216797
iter 10000, train_loss 129.58482360839844
eval_loss: 135.5439453125 psnr: 27.392364501953125
iter 10050, train_loss 142.49754333496094
eval_loss: 133.72450256347656 psnr: 27.427812576293945
iter 10100, train_loss 141.3995819091797
eval_loss: 133.04595947265625 psnr: 27.467870712280273
iter 10150, train_loss 125.0508804321289
eval_loss: 131.6232452392578 psnr: 27.50990867614746
iter 10200, train_loss 123.6343994140625
eval_loss: 130.26071166992188 psnr: 27.532299041748047
iter 10250, train_loss 135.01707458496094
eval_loss: 129.62957763671875 psnr: 27.555692672729492
iter 10300, train_loss 146.98922729492188
eval_loss: 129.32534790039062 psnr: 27.572546005249023
iter 10350, train_loss 118.43096160888672
eval_loss: 128.45623779296875 psnr: 27.606765747070312
iter 10400, train_loss 106.84073638916016
eval_loss: 126.7652359008789 psnr: 27.689287185668945
iter 10450, train_loss 123.40174865722656
eval_loss: 126.01191711425781 psnr: 27.696456909179688
iter 10500, train_loss 122.3184585571289
eval_loss: 124.92595672607422 psnr: 27.74434471130371
iter 10550, train_loss 124.24674224853516
eval_loss: 123.63299560546875 psnr: 27.778051376342773
iter 10600, train_loss 117.73133850097656
eval_loss: 123.08374786376953 psnr: 27.82209014892578
iter 10650, train_loss 111.06304168701172
eval_loss: 122.50038146972656 psnr: 27.868694305419922
iter 10700, train_loss 103.6218490600586
eval_loss: 120.4530029296875 psnr: 27.88756561279297
iter 10750, train_loss 117.16999816894531
eval_loss: 120.43423461914062 psnr: 27.91405487060547
iter 10800, train_loss 116.03267669677734
eval_loss: 119.38395690917969 psnr: 27.910079956054688
iter 10850, train_loss 112.59449768066406
eval_loss: 118.35281372070312 psnr: 28.00447654724121
iter 10900, train_loss 125.70670318603516
eval_loss: 117.1072006225586 psnr: 28.046525955200195
iter 10950, train_loss 106.900146484375
eval_loss: 116.58658599853516 psnr: 28.018232345581055
iter 11000, train_loss 115.4955825805664
eval_loss: 115.75221252441406 psnr: 28.078922271728516
iter 11050, train_loss 117.2667236328125
eval_loss: 115.09636688232422 psnr: 28.115135192871094
iter 11100, train_loss 115.70820617675781
eval_loss: 114.55335998535156 psnr: 28.109792709350586
iter 11150, train_loss 110.46075439453125
eval_loss: 113.06770324707031 psnr: 28.210739135742188
iter 11200, train_loss 121.71746063232422
eval_loss: 112.42328643798828 psnr: 28.24180030822754
iter 11250, train_loss 91.83499145507812
eval_loss: 112.3580322265625 psnr: 28.21434211730957
iter 11300, train_loss 105.28618621826172
eval_loss: 111.38755798339844 psnr: 28.24115562438965
iter 11350, train_loss 114.56825256347656
eval_loss: 111.20305633544922 psnr: 28.26154136657715
iter 11400, train_loss 103.06654357910156
eval_loss: 110.14175415039062 psnr: 28.28746223449707
iter 11450, train_loss 108.66207122802734
eval_loss: 109.04679870605469 psnr: 28.351791381835938
iter 11500, train_loss 110.72108459472656
eval_loss: 108.24744415283203 psnr: 28.402883529663086
iter 11550, train_loss 102.0847396850586
eval_loss: 108.54583740234375 psnr: 28.411788940429688
iter 11600, train_loss 100.4759750366211
eval_loss: 107.18264770507812 psnr: 28.445316314697266
iter 11650, train_loss 92.66267395019531
eval_loss: 106.36457061767578 psnr: 28.461118698120117
iter 11700, train_loss 127.77638244628906
eval_loss: 105.034912109375 psnr: 28.512739181518555
iter 11750, train_loss 116.58003234863281
eval_loss: 104.99958038330078 psnr: 28.551780700683594
iter 11800, train_loss 84.80779266357422
eval_loss: 103.82209777832031 psnr: 28.56977653503418
iter 11850, train_loss 87.79496765136719
eval_loss: 104.67877960205078 psnr: 28.564918518066406
iter 11900, train_loss 99.52559661865234
eval_loss: 102.4310073852539 psnr: 28.6528377532959
iter 11950, train_loss 99.80347442626953
eval_loss: 102.8900375366211 psnr: 28.58349609375
iter 12000, train_loss 83.67562103271484
eval_loss: 101.9799575805664 psnr: 28.67980194091797
iter 12050, train_loss 92.55721282958984
eval_loss: 101.28813934326172 psnr: 28.730918884277344
iter 12100, train_loss 100.67731475830078
eval_loss: 101.3428955078125 psnr: 28.73720359802246
iter 12150, train_loss 87.78900909423828
eval_loss: 100.6421890258789 psnr: 28.76063346862793
iter 12200, train_loss 93.32746887207031
eval_loss: 99.45853424072266 psnr: 28.78268051147461
iter 12250, train_loss 105.7219467163086
eval_loss: 99.44248962402344 psnr: 28.810810089111328
iter 12300, train_loss 90.49141693115234
eval_loss: 98.94903564453125 psnr: 28.83007049560547
iter 12350, train_loss 104.1601791381836
eval_loss: 97.09851837158203 psnr: 28.912790298461914
iter 12400, train_loss 92.83904266357422
eval_loss: 96.61737823486328 psnr: 28.927047729492188
iter 12450, train_loss 90.7115707397461
eval_loss: 95.83213806152344 psnr: 28.935195922851562
iter 12500, train_loss 80.2310562133789
eval_loss: 94.98086547851562 psnr: 28.996187210083008
iter 12550, train_loss 88.51781463623047
eval_loss: 95.33033752441406 psnr: 28.961341857910156
iter 12600, train_loss 92.20697021484375
eval_loss: 94.18646240234375 psnr: 29.068193435668945
iter 12650, train_loss 91.7306900024414
eval_loss: 93.98947143554688 psnr: 29.065460205078125
iter 12700, train_loss 89.25526428222656
eval_loss: 93.9426498413086 psnr: 29.039966583251953
iter 12750, train_loss 88.39034271240234
eval_loss: 92.47589111328125 psnr: 29.134613037109375
iter 12800, train_loss 86.2998046875
eval_loss: 91.85920715332031 psnr: 29.148534774780273
iter 12850, train_loss 85.3815689086914
eval_loss: 91.59241485595703 psnr: 29.18634796142578
iter 12900, train_loss 88.3055648803711
eval_loss: 91.04935455322266 psnr: 29.165172576904297
iter 12950, train_loss 89.29192352294922
eval_loss: 92.38776397705078 psnr: 29.195446014404297
iter 13000, train_loss 85.9573974609375
eval_loss: 89.56137084960938 psnr: 29.230979919433594
iter 13050, train_loss 75.8096923828125
eval_loss: 90.29544830322266 psnr: 29.232120513916016
iter 13100, train_loss 80.33572387695312
eval_loss: 89.10807800292969 psnr: 29.26727294921875
iter 13150, train_loss 73.62338256835938
eval_loss: 90.66077423095703 psnr: 29.27010726928711
iter 13200, train_loss 83.2331314086914
eval_loss: 88.67436218261719 psnr: 29.285367965698242
iter 13250, train_loss 76.83242797851562
eval_loss: 88.43902587890625 psnr: 29.33107566833496
iter 13300, train_loss 77.67679595947266
eval_loss: 88.23847961425781 psnr: 29.37525749206543
iter 13350, train_loss 91.88040924072266
eval_loss: 86.65948486328125 psnr: 29.464475631713867
iter 13400, train_loss 87.83499145507812
eval_loss: 86.36306762695312 psnr: 29.42559814453125
iter 13450, train_loss 76.39390563964844
eval_loss: 86.55577087402344 psnr: 29.439184188842773
iter 13500, train_loss 85.44293212890625
eval_loss: 85.62049865722656 psnr: 29.506820678710938
iter 13550, train_loss 83.27664184570312
eval_loss: 84.49905395507812 psnr: 29.53925132751465
iter 13600, train_loss 75.99868774414062
eval_loss: 85.76444244384766 psnr: 29.455957412719727
iter 13650, train_loss 80.8672866821289
eval_loss: 84.3493881225586 psnr: 29.533994674682617
iter 13700, train_loss 80.83308410644531
eval_loss: 83.842041015625 psnr: 29.59866714477539
iter 13750, train_loss 77.0035171508789
eval_loss: 83.76024627685547 psnr: 29.582839965820312
iter 13800, train_loss 80.10595703125
eval_loss: 82.48761749267578 psnr: 29.62967300415039
iter 13850, train_loss 78.96073913574219
eval_loss: 82.89273834228516 psnr: 29.64288330078125
iter 13900, train_loss 77.05775451660156
eval_loss: 82.04589080810547 psnr: 29.692462921142578
iter 13950, train_loss 81.20072174072266
eval_loss: 81.88240051269531 psnr: 29.70781898498535
iter 14000, train_loss 66.06009674072266
eval_loss: 82.03851318359375 psnr: 29.681529998779297
iter 14050, train_loss 85.14446258544922
eval_loss: 81.15147399902344 psnr: 29.673994064331055
iter 14100, train_loss 89.39984130859375
eval_loss: 80.65898132324219 psnr: 29.750686645507812
iter 14150, train_loss 69.62721252441406
eval_loss: 80.9911117553711 psnr: 29.723115921020508
iter 14200, train_loss 75.53246307373047
eval_loss: 80.11554718017578 psnr: 29.815662384033203
iter 14250, train_loss 74.09637451171875
eval_loss: 79.57865905761719 psnr: 29.826026916503906
iter 14300, train_loss 75.79723358154297
eval_loss: 78.65283966064453 psnr: 29.889135360717773
iter 14350, train_loss 72.24413299560547
eval_loss: 78.96590423583984 psnr: 29.852798461914062
iter 14400, train_loss 80.6007308959961
eval_loss: 78.61304473876953 psnr: 29.828899383544922
iter 14450, train_loss 74.41259002685547
eval_loss: 77.4964599609375 psnr: 29.921445846557617
iter 14500, train_loss 66.21317291259766
eval_loss: 78.1063232421875 psnr: 29.89017677307129
iter 14550, train_loss 64.90767669677734
eval_loss: 77.49494934082031 psnr: 29.971906661987305
iter 14600, train_loss 65.4575424194336
eval_loss: 76.5870361328125 psnr: 29.984350204467773
iter 14650, train_loss 72.77852630615234
eval_loss: 76.6654281616211 psnr: 29.945831298828125
iter 14700, train_loss 67.202392578125
eval_loss: 77.12794494628906 psnr: 29.951284408569336
iter 14750, train_loss 63.06706619262695
eval_loss: 75.94435119628906 psnr: 30.017662048339844
iter 14800, train_loss 62.60413360595703
eval_loss: 77.27652740478516 psnr: 29.978078842163086
iter 14850, train_loss 72.08043670654297
eval_loss: 74.96946716308594 psnr: 30.110788345336914
iter 14900, train_loss 67.73928833007812
eval_loss: 75.35767364501953 psnr: 30.147661209106445
iter 14950, train_loss 70.72804260253906
eval_loss: 74.19566345214844 psnr: 30.147375106811523
iter 15000, train_loss 72.0337142944336
eval_loss: 74.738037109375 psnr: 30.117664337158203
iter 15050, train_loss 65.82416534423828
eval_loss: 73.97289276123047 psnr: 30.13021469116211
iter 15100, train_loss 60.94133377075195
eval_loss: 73.46968841552734 psnr: 30.1842098236084
iter 15150, train_loss 66.551513671875
eval_loss: 74.90860748291016 psnr: 30.12848472595215
iter 15200, train_loss 61.432613372802734
eval_loss: 72.81867980957031 psnr: 30.2447509765625
iter 15250, train_loss 68.32588958740234
eval_loss: 72.43880462646484 psnr: 30.262935638427734
iter 15300, train_loss 64.27409362792969
eval_loss: 72.32051849365234 psnr: 30.2486515045166
iter 15350, train_loss 72.48626708984375
eval_loss: 72.62510681152344 psnr: 30.271625518798828
iter 15400, train_loss 77.09310150146484
eval_loss: 72.777587890625 psnr: 30.282150268554688
iter 15450, train_loss 59.70481491088867
eval_loss: 71.06012725830078 psnr: 30.354055404663086
iter 15500, train_loss 59.913551330566406
eval_loss: 71.91980743408203 psnr: 30.262666702270508
iter 15550, train_loss 66.87142181396484
eval_loss: 70.575439453125 psnr: 30.333044052124023
iter 15600, train_loss 67.78258514404297
eval_loss: 70.89803314208984 psnr: 30.363008499145508
iter 15650, train_loss 65.24169158935547
eval_loss: 69.66593933105469 psnr: 30.426326751708984
iter 15700, train_loss 62.49542236328125
eval_loss: 71.09524536132812 psnr: 30.323068618774414
iter 15750, train_loss 70.51612854003906
eval_loss: 69.52840423583984 psnr: 30.4335994720459
iter 15800, train_loss 62.4947395324707
eval_loss: 70.11444854736328 psnr: 30.444725036621094
iter 15850, train_loss 70.20247650146484
eval_loss: 69.00360870361328 psnr: 30.507930755615234
iter 15900, train_loss 57.1769905090332
eval_loss: 69.2596206665039 psnr: 30.529462814331055
iter 15950, train_loss 64.11396789550781
eval_loss: 68.11394500732422 psnr: 30.525705337524414
iter 16000, train_loss 70.16301727294922
eval_loss: 69.0560531616211 psnr: 30.449722290039062
iter 16050, train_loss 67.54518127441406
eval_loss: 67.59112548828125 psnr: 30.549671173095703
iter 16100, train_loss 58.75456619262695
eval_loss: 69.37641143798828 psnr: 30.480138778686523
iter 16150, train_loss 70.20024871826172
eval_loss: 68.00623321533203 psnr: 30.51028060913086
iter 16200, train_loss 58.930965423583984
eval_loss: 67.36212158203125 psnr: 30.587617874145508
iter 16250, train_loss 64.7931900024414
eval_loss: 67.41694641113281 psnr: 30.600616455078125
iter 16300, train_loss 68.7022705078125
eval_loss: 66.65287017822266 psnr: 30.619497299194336
iter 16350, train_loss 61.76043701171875
eval_loss: 67.52147674560547 psnr: 30.57288932800293
iter 16400, train_loss 62.3349723815918
eval_loss: 65.98955535888672 psnr: 30.628067016601562
iter 16450, train_loss 57.00879669189453
eval_loss: 67.26075744628906 psnr: 30.581575393676758
iter 16500, train_loss 66.34447479248047
eval_loss: 66.3858413696289 psnr: 30.69426918029785
iter 16550, train_loss 53.2050895690918
eval_loss: 65.29471588134766 psnr: 30.69020652770996
iter 16600, train_loss 56.569252014160156
eval_loss: 65.34445190429688 psnr: 30.778654098510742
iter 16650, train_loss 56.96773910522461
eval_loss: 66.02957153320312 psnr: 30.75193977355957
iter 16700, train_loss 58.96438217163086
eval_loss: 65.0730209350586 psnr: 30.740219116210938
iter 16750, train_loss 68.72586822509766
eval_loss: 64.91215515136719 psnr: 30.77216148376465
iter 16800, train_loss 59.24567413330078
eval_loss: 63.60378646850586 psnr: 30.87329864501953
iter 16850, train_loss 60.61519241333008
eval_loss: 63.98904800415039 psnr: 30.849807739257812
iter 16900, train_loss 62.44448471069336
eval_loss: 64.41732788085938 psnr: 30.82529067993164
iter 16950, train_loss 59.41984939575195
eval_loss: 62.71451950073242 psnr: 30.973989486694336
iter 17000, train_loss 58.9846076965332
eval_loss: 64.01155090332031 psnr: 30.81941795349121
iter 17050, train_loss 63.24369430541992
eval_loss: 63.64260482788086 psnr: 30.893625259399414
iter 17100, train_loss 52.3164176940918
eval_loss: 63.06296920776367 psnr: 30.946208953857422
iter 17150, train_loss 61.01837921142578
eval_loss: 64.05146026611328 psnr: 30.84777069091797
iter 17200, train_loss 52.15452194213867
eval_loss: 62.01305389404297 psnr: 30.983736038208008
iter 17250, train_loss 58.423004150390625
eval_loss: 61.673858642578125 psnr: 31.04592514038086
iter 17300, train_loss 54.097347259521484
eval_loss: 61.60458755493164 psnr: 31.013940811157227
iter 17350, train_loss 62.23043441772461
eval_loss: 61.79159164428711 psnr: 30.927997589111328
iter 17400, train_loss 54.973388671875
eval_loss: 61.97819519042969 psnr: 31.02216148376465
iter 17450, train_loss 57.67763137817383
eval_loss: 61.48369216918945 psnr: 31.027454376220703
iter 17500, train_loss 56.684722900390625
eval_loss: 61.44929504394531 psnr: 31.111474990844727
iter 17550, train_loss 53.85700607299805
eval_loss: 61.91352462768555 psnr: 31.00826072692871
iter 17600, train_loss 52.1572380065918
eval_loss: 60.72981262207031 psnr: 31.067974090576172
iter 17650, train_loss 61.094459533691406
eval_loss: 60.56212615966797 psnr: 31.050861358642578
iter 17700, train_loss 61.419105529785156
eval_loss: 59.29775619506836 psnr: 31.177165985107422
iter 17750, train_loss 60.280311584472656
eval_loss: 60.12668991088867 psnr: 31.153715133666992
iter 17800, train_loss 60.217891693115234
eval_loss: 60.472110748291016 psnr: 31.133975982666016
iter 17850, train_loss 66.44295501708984
eval_loss: 59.545413970947266 psnr: 31.175453186035156
iter 17900, train_loss 61.13275909423828
eval_loss: 59.50900650024414 psnr: 31.15560531616211
iter 17950, train_loss 53.45968246459961
eval_loss: 58.845821380615234 psnr: 31.234149932861328
iter 18000, train_loss 50.070030212402344
eval_loss: 58.766719818115234 psnr: 31.235261917114258
iter 18050, train_loss 63.44807815551758
eval_loss: 60.55046463012695 psnr: 31.15239715576172
iter 18100, train_loss 49.1982421875
eval_loss: 59.72233200073242 psnr: 31.2056941986084
iter 18150, train_loss 54.969024658203125
eval_loss: 58.24354934692383 psnr: 31.319210052490234
iter 18200, train_loss 50.24755859375
eval_loss: 58.565093994140625 psnr: 31.262428283691406
iter 18250, train_loss 54.27094650268555
eval_loss: 57.5539436340332 psnr: 31.310588836669922
iter 18300, train_loss 52.3990478515625
eval_loss: 58.76651382446289 psnr: 31.16080665588379
iter 18350, train_loss 50.342620849609375
eval_loss: 58.19937515258789 psnr: 31.336322784423828
iter 18400, train_loss 54.91569137573242
eval_loss: 58.246681213378906 psnr: 31.27979278564453
iter 18450, train_loss 44.980220794677734
eval_loss: 59.50007629394531 psnr: 31.159608840942383
iter 18500, train_loss 51.00758361816406
eval_loss: 56.42219543457031 psnr: 31.43171501159668
iter 18550, train_loss 48.96275329589844
eval_loss: 56.73081588745117 psnr: 31.4464054107666
iter 18600, train_loss 52.07969284057617
eval_loss: 57.56527328491211 psnr: 31.3718204498291
iter 18650, train_loss 47.05222702026367
eval_loss: 56.661842346191406 psnr: 31.363786697387695
iter 18700, train_loss 55.52192306518555
eval_loss: 58.18743133544922 psnr: 31.282743453979492
iter 18750, train_loss 50.74510192871094
eval_loss: 55.61587142944336 psnr: 31.52199935913086
iter 18800, train_loss 54.44270706176758
eval_loss: 57.22745132446289 psnr: 31.298009872436523
iter 18850, train_loss 53.733070373535156
eval_loss: 56.35776138305664 psnr: 31.405702590942383
iter 18900, train_loss 46.73685073852539
eval_loss: 55.842281341552734 psnr: 31.501821517944336
iter 18950, train_loss 52.4693717956543
eval_loss: 55.399986267089844 psnr: 31.522741317749023
iter 19000, train_loss 51.401222229003906
eval_loss: 54.87248611450195 psnr: 31.64073944091797
iter 19050, train_loss 54.017616271972656
eval_loss: 55.26313781738281 psnr: 31.54555892944336
iter 19100, train_loss 50.98895263671875
eval_loss: 54.63542556762695 psnr: 31.569124221801758
iter 19150, train_loss 48.06772994995117
eval_loss: 54.845909118652344 psnr: 31.555221557617188
iter 19200, train_loss 51.8879280090332
eval_loss: 55.551387786865234 psnr: 31.525726318359375
iter 19250, train_loss 56.312591552734375
eval_loss: 53.797542572021484 psnr: 31.66083526611328
iter 19300, train_loss 48.41518783569336
eval_loss: 54.43864440917969 psnr: 31.630277633666992
iter 19350, train_loss 54.04159164428711
eval_loss: 54.41209030151367 psnr: 31.625917434692383
iter 19400, train_loss 48.54759979248047
eval_loss: 53.070556640625 psnr: 31.719921112060547
iter 19450, train_loss 52.35768508911133
eval_loss: 54.25963592529297 psnr: 31.56291961669922
iter 19500, train_loss 51.98161697387695
eval_loss: 53.898502349853516 psnr: 31.691450119018555
iter 19550, train_loss 54.50545883178711
eval_loss: 53.22964859008789 psnr: 31.696338653564453
iter 19600, train_loss 55.02002716064453
eval_loss: 53.42495346069336 psnr: 31.710540771484375
iter 19650, train_loss 47.87223815917969
eval_loss: 53.362545013427734 psnr: 31.75613784790039
iter 19700, train_loss 50.552459716796875
eval_loss: 52.01295852661133 psnr: 31.78167724609375
iter 19750, train_loss 47.62895965576172
eval_loss: 52.34442901611328 psnr: 31.799104690551758
iter 19800, train_loss 55.027442932128906
eval_loss: 52.54731369018555 psnr: 31.762283325195312
iter 19850, train_loss 45.6888313293457
eval_loss: 52.315101623535156 psnr: 31.785493850708008
iter 19900, train_loss 49.25947952270508
eval_loss: 52.836029052734375 psnr: 31.78744125366211
iter 19950, train_loss 43.78841781616211
eval_loss: 52.90616226196289 psnr: 31.74908447265625
iter 20000, train_loss 46.520477294921875
eval_loss: 51.56098175048828 psnr: 31.855504989624023
iter 20050, train_loss 47.790340423583984
eval_loss: 51.96510696411133 psnr: 31.855031967163086
iter 20100, train_loss 50.01542663574219
eval_loss: 52.13064956665039 psnr: 31.7946720123291
iter 20150, train_loss 42.2540168762207
eval_loss: 50.860260009765625 psnr: 31.849916458129883
iter 20200, train_loss 48.444976806640625
eval_loss: 51.00477981567383 psnr: 31.891786575317383
iter 20250, train_loss 47.840492248535156
eval_loss: 51.190574645996094 psnr: 31.88457679748535
iter 20300, train_loss 44.32632827758789
eval_loss: 51.09269332885742 psnr: 31.886215209960938
iter 20350, train_loss 45.012657165527344
eval_loss: 50.70301818847656 psnr: 31.88732147216797
iter 20400, train_loss 47.0223503112793
eval_loss: 51.97526550292969 psnr: 31.818927764892578
iter 20450, train_loss 42.32978057861328
eval_loss: 49.914817810058594 psnr: 32.00092315673828
iter 20500, train_loss 46.49570846557617
eval_loss: 50.93359375 psnr: 31.959123611450195
iter 20550, train_loss 47.62030029296875
eval_loss: 50.33137512207031 psnr: 31.97663688659668
iter 20600, train_loss 46.00576400756836
eval_loss: 49.68556213378906 psnr: 32.014991760253906
iter 20650, train_loss 47.608306884765625
eval_loss: 49.60060119628906 psnr: 32.044349670410156
iter 20700, train_loss 44.00788497924805
eval_loss: 50.006126403808594 psnr: 32.01982498168945
iter 20750, train_loss 52.25996017456055
eval_loss: 49.47064208984375 psnr: 32.02075958251953
iter 20800, train_loss 43.17344284057617
eval_loss: 49.342857360839844 psnr: 32.0673828125
iter 20850, train_loss 48.16680908203125
eval_loss: 49.076683044433594 psnr: 32.16584396362305
iter 20900, train_loss 55.127349853515625
eval_loss: 48.51981735229492 psnr: 32.09506607055664
iter 20950, train_loss 45.51117706298828
eval_loss: 48.61732482910156 psnr: 32.12639617919922
iter 21000, train_loss 46.80986404418945
eval_loss: 48.87541580200195 psnr: 32.14314270019531
iter 21050, train_loss 45.83013153076172
eval_loss: 48.80221176147461 psnr: 32.137020111083984
iter 21100, train_loss 43.277587890625
eval_loss: 48.695457458496094 psnr: 32.15138244628906
iter 21150, train_loss 41.491676330566406
eval_loss: 49.39997863769531 psnr: 32.05940246582031
iter 21200, train_loss 42.351619720458984
eval_loss: 48.12638473510742 psnr: 32.13557434082031
iter 21250, train_loss 45.027523040771484
eval_loss: 47.80354690551758 psnr: 32.16820526123047
iter 21300, train_loss 43.749752044677734
eval_loss: 48.38776779174805 psnr: 32.095767974853516
iter 21350, train_loss 36.41223907470703
eval_loss: 48.327171325683594 psnr: 32.20140075683594
iter 21400, train_loss 45.24772644042969
eval_loss: 47.760475158691406 psnr: 32.24897003173828
iter 21450, train_loss 42.25277328491211
eval_loss: 47.63636779785156 psnr: 32.25416946411133
iter 21500, train_loss 47.2606315612793
eval_loss: 47.2176628112793 psnr: 32.26236343383789
iter 21550, train_loss 39.53609848022461
eval_loss: 46.89939880371094 psnr: 32.293766021728516
iter 21600, train_loss 34.678009033203125
eval_loss: 48.300453186035156 psnr: 32.11350631713867
iter 21650, train_loss 44.3829460144043
eval_loss: 47.7132453918457 psnr: 32.1796989440918
iter 21700, train_loss 47.10641098022461
eval_loss: 47.831180572509766 psnr: 32.260986328125
iter 21750, train_loss 42.1953239440918
eval_loss: 47.878822326660156 psnr: 32.20369338989258
iter 21800, train_loss 50.269222259521484
eval_loss: 46.21274185180664 psnr: 32.39751052856445
iter 21850, train_loss 44.149383544921875
eval_loss: 46.365753173828125 psnr: 32.337528228759766
iter 21900, train_loss 42.2376594543457
eval_loss: 48.670860290527344 psnr: 32.282955169677734
iter 21950, train_loss 41.04610061645508
eval_loss: 46.015113830566406 psnr: 32.35284423828125
iter 22000, train_loss 36.72307586669922
eval_loss: 46.28688049316406 psnr: 32.377464294433594
iter 22050, train_loss 33.329124450683594
eval_loss: 46.53458023071289 psnr: 32.24950408935547
iter 22100, train_loss 41.71171951293945
eval_loss: 45.783668518066406 psnr: 32.4345817565918
iter 22150, train_loss 41.73032760620117
eval_loss: 46.21228790283203 psnr: 32.3786506652832
iter 22200, train_loss 45.05752182006836
eval_loss: 45.1861572265625 psnr: 32.46648025512695
iter 22250, train_loss 40.33877182006836
eval_loss: 44.99543380737305 psnr: 32.481781005859375
iter 22300, train_loss 41.5847282409668
eval_loss: 44.951995849609375 psnr: 32.46724319458008
iter 22350, train_loss 39.056312561035156
eval_loss: 46.061702728271484 psnr: 32.42136001586914
iter 22400, train_loss 40.83087921142578
eval_loss: 44.70473098754883 psnr: 32.48697280883789
iter 22450, train_loss 39.905296325683594
eval_loss: 45.02384948730469 psnr: 32.55038833618164
iter 22500, train_loss 41.08451461791992
eval_loss: 45.19593811035156 psnr: 32.44170379638672
iter 22550, train_loss 45.07495880126953
eval_loss: 44.98809814453125 psnr: 32.4666633605957
iter 22600, train_loss 38.73319625854492
eval_loss: 45.69220733642578 psnr: 32.43718338012695
iter 22650, train_loss 41.40475082397461
eval_loss: 44.693328857421875 psnr: 32.51333236694336
iter 22700, train_loss 41.98139190673828
eval_loss: 44.0848503112793 psnr: 32.54629135131836
iter 22750, train_loss 38.694828033447266
eval_loss: 44.91997528076172 psnr: 32.5691032409668
iter 22800, train_loss 37.40934371948242
eval_loss: 43.73988342285156 psnr: 32.666778564453125
iter 22850, train_loss 43.917259216308594
eval_loss: 43.804588317871094 psnr: 32.62109375
iter 22900, train_loss 40.99872970581055
eval_loss: 43.934303283691406 psnr: 32.64560317993164
iter 22950, train_loss 38.11792755126953
eval_loss: 45.34617614746094 psnr: 32.48332214355469
iter 23000, train_loss 36.7818603515625
eval_loss: 43.63011169433594 psnr: 32.61547088623047
iter 23050, train_loss 36.023555755615234
eval_loss: 43.47223663330078 psnr: 32.62539291381836
iter 23100, train_loss 45.941219329833984
eval_loss: 44.03376770019531 psnr: 32.562965393066406
iter 23150, train_loss 40.669193267822266
eval_loss: 43.05220031738281 psnr: 32.71426010131836
iter 23200, train_loss 41.73771286010742
eval_loss: 42.568641662597656 psnr: 32.74219512939453
iter 23250, train_loss 37.46514892578125
eval_loss: 42.95313262939453 psnr: 32.67129898071289
iter 23300, train_loss 36.74089813232422
eval_loss: 43.71417999267578 psnr: 32.64658737182617
iter 23350, train_loss 37.02501678466797
eval_loss: 43.43769836425781 psnr: 32.70448684692383
iter 23400, train_loss 43.413997650146484
eval_loss: 42.88202667236328 psnr: 32.697940826416016
iter 23450, train_loss 40.126338958740234
eval_loss: 42.36001968383789 psnr: 32.74155044555664
iter 23500, train_loss 38.42115020751953
eval_loss: 43.02571105957031 psnr: 32.667823791503906
iter 23550, train_loss 35.79112243652344
eval_loss: 42.745452880859375 psnr: 32.724143981933594
iter 23600, train_loss 36.066017150878906
eval_loss: 43.41394805908203 psnr: 32.625919342041016
iter 23650, train_loss 36.070926666259766
eval_loss: 42.484153747558594 psnr: 32.74013900756836
iter 23700, train_loss 36.022029876708984
eval_loss: 42.49021530151367 psnr: 32.8282585144043
iter 23750, train_loss 36.754817962646484
eval_loss: 42.926082611083984 psnr: 32.723323822021484
iter 23800, train_loss 40.65298080444336
eval_loss: 42.073604583740234 psnr: 32.83198928833008
iter 23850, train_loss 43.4000129699707
eval_loss: 41.32624816894531 psnr: 32.87086868286133
iter 23900, train_loss 40.70952224731445
eval_loss: 41.91212844848633 psnr: 32.79854965209961
iter 23950, train_loss 35.737525939941406
eval_loss: 42.11979675292969 psnr: 32.866153717041016
iter 24000, train_loss 38.15346908569336
eval_loss: 41.61040496826172 psnr: 32.83858108520508
iter 24050, train_loss 32.581565856933594
eval_loss: 42.13092041015625 psnr: 32.783443450927734
iter 24100, train_loss 38.266212463378906
eval_loss: 42.59528350830078 psnr: 32.82465744018555
iter 24150, train_loss 39.44930648803711
eval_loss: 41.45406723022461 psnr: 32.9021110534668
iter 24200, train_loss 43.84828567504883
eval_loss: 41.4962272644043 psnr: 32.8575553894043
iter 24250, train_loss 32.81622314453125
eval_loss: 41.275360107421875 psnr: 32.86585998535156
iter 24300, train_loss 35.79549789428711
eval_loss: 42.014251708984375 psnr: 32.82494354248047
iter 24350, train_loss 35.16131591796875
eval_loss: 43.14912033081055 psnr: 32.73271560668945
iter 24400, train_loss 36.37263488769531
eval_loss: 41.69339370727539 psnr: 32.8402099609375
iter 24450, train_loss 36.00459671020508
eval_loss: 40.56547546386719 psnr: 32.98597717285156
iter 24500, train_loss 35.985137939453125
eval_loss: 42.63557434082031 psnr: 32.764347076416016
iter 24550, train_loss 34.01820373535156
eval_loss: 41.639102935791016 psnr: 32.89835739135742
iter 24600, train_loss 37.57215118408203
eval_loss: 40.27113723754883 psnr: 32.97645950317383
iter 24650, train_loss 33.51960754394531
eval_loss: 40.082942962646484 psnr: 33.058143615722656
iter 24700, train_loss 39.349365234375
eval_loss: 40.72773361206055 psnr: 32.98618698120117
iter 24750, train_loss 38.23456954956055
eval_loss: 40.47214889526367 psnr: 32.945716857910156
iter 24800, train_loss 34.77204895019531
eval_loss: 40.208133697509766 psnr: 33.04893112182617
iter 24850, train_loss 35.2774772644043
eval_loss: 39.8804931640625 psnr: 33.0368537902832
iter 24900, train_loss 37.178001403808594
eval_loss: 40.42045211791992 psnr: 32.9350700378418
iter 24950, train_loss 42.2116584777832
eval_loss: 40.70784378051758 psnr: 32.920902252197266
iter 25000, train_loss 35.713958740234375
eval_loss: 39.42336654663086 psnr: 33.091304779052734
iter 25050, train_loss 37.665279388427734
eval_loss: 39.4879150390625 psnr: 33.071468353271484
iter 25100, train_loss 36.516387939453125
eval_loss: 39.457122802734375 psnr: 33.01424789428711
iter 25150, train_loss 37.17877960205078
eval_loss: 39.25899124145508 psnr: 33.1165657043457
iter 25200, train_loss 32.66451644897461
eval_loss: 38.760032653808594 psnr: 33.17516326904297
iter 25250, train_loss 34.329498291015625
eval_loss: 40.754173278808594 psnr: 33.053062438964844
iter 25300, train_loss 33.5694465637207
eval_loss: 39.43910598754883 psnr: 33.14217758178711
iter 25350, train_loss 31.51594352722168
eval_loss: 39.59419631958008 psnr: 33.106361389160156
iter 25400, train_loss 35.16169357299805
eval_loss: 39.78907775878906 psnr: 33.1680793762207
iter 25450, train_loss 33.508392333984375
eval_loss: 38.70685577392578 psnr: 33.144691467285156
iter 25500, train_loss 35.9835205078125
eval_loss: 38.93608474731445 psnr: 33.12269973754883
iter 25550, train_loss 35.851898193359375
eval_loss: 38.49158477783203 psnr: 33.14947509765625
iter 25600, train_loss 36.128448486328125
eval_loss: 39.88631820678711 psnr: 33.0783805847168
iter 25650, train_loss 31.75455665588379
eval_loss: 39.19024658203125 psnr: 33.1065673828125
iter 25700, train_loss 35.433589935302734
eval_loss: 38.300228118896484 psnr: 33.19070053100586
iter 25750, train_loss 35.18363952636719
eval_loss: 39.28618621826172 psnr: 33.07305145263672
iter 25800, train_loss 35.46438217163086
eval_loss: 38.626590728759766 psnr: 33.193538665771484
iter 25850, train_loss 34.01047897338867
eval_loss: 38.439361572265625 psnr: 33.17243576049805
iter 25900, train_loss 42.20768356323242
eval_loss: 39.286373138427734 psnr: 33.16379928588867
iter 25950, train_loss 30.7635555267334
eval_loss: 38.463829040527344 psnr: 33.226200103759766
iter 26000, train_loss 36.207210540771484
eval_loss: 38.65964889526367 psnr: 33.22355270385742
iter 26050, train_loss 32.572505950927734
eval_loss: 37.797523498535156 psnr: 33.29911422729492
iter 26100, train_loss 41.62294387817383
eval_loss: 39.56036376953125 psnr: 33.05781173706055
iter 26150, train_loss 44.87722396850586
eval_loss: 39.13771057128906 psnr: 33.13568115234375
iter 26200, train_loss 39.624332427978516
eval_loss: 37.101505279541016 psnr: 33.378257751464844
iter 26250, train_loss 30.8892765045166
eval_loss: 37.69818115234375 psnr: 33.36197280883789
iter 26300, train_loss 33.89546585083008
eval_loss: 38.14715576171875 psnr: 33.289730072021484
iter 26350, train_loss 34.37860107421875
eval_loss: 38.167724609375 psnr: 33.25202941894531
iter 26400, train_loss 32.228294372558594
eval_loss: 38.253089904785156 psnr: 33.251304626464844
iter 26450, train_loss 32.55217361450195
eval_loss: 37.7832145690918 psnr: 33.35383987426758
iter 26500, train_loss 30.38490867614746
eval_loss: 37.27116394042969 psnr: 33.36338424682617
iter 26550, train_loss 31.739164352416992
eval_loss: 38.1949348449707 psnr: 33.286048889160156
iter 26600, train_loss 32.3366813659668
eval_loss: 37.048397064208984 psnr: 33.348026275634766
iter 26650, train_loss 27.325220108032227
eval_loss: 37.14418029785156 psnr: 33.3972282409668
iter 26700, train_loss 33.4864616394043
eval_loss: 37.95915985107422 psnr: 33.242984771728516
iter 26750, train_loss 31.982351303100586
eval_loss: 36.761802673339844 psnr: 33.456172943115234
iter 26800, train_loss 37.85088348388672
eval_loss: 37.02264404296875 psnr: 33.40609359741211
iter 26850, train_loss 35.89278793334961
eval_loss: 36.92211151123047 psnr: 33.44388961791992
iter 26900, train_loss 32.00352096557617
eval_loss: 36.17317199707031 psnr: 33.5084114074707
iter 26950, train_loss 28.50606346130371
eval_loss: 37.06582260131836 psnr: 33.45185852050781
iter 27000, train_loss 37.59443283081055
eval_loss: 37.77241516113281 psnr: 33.342594146728516
iter 27050, train_loss 32.0941047668457
eval_loss: 36.907466888427734 psnr: 33.372562408447266
iter 27100, train_loss 34.70855712890625
eval_loss: 36.67424392700195 psnr: 33.47377395629883
iter 27150, train_loss 33.283023834228516
eval_loss: 36.7408332824707 psnr: 33.40269088745117
iter 27200, train_loss 31.676727294921875
eval_loss: 36.427696228027344 psnr: 33.402225494384766
iter 27250, train_loss 30.689105987548828
eval_loss: 36.623294830322266 psnr: 33.510135650634766
iter 27300, train_loss 29.69727897644043
eval_loss: 35.92204284667969 psnr: 33.53418731689453
iter 27350, train_loss 28.587865829467773
eval_loss: 36.65077590942383 psnr: 33.447662353515625
iter 27400, train_loss 35.86185836791992
eval_loss: 35.67262649536133 psnr: 33.55760955810547
iter 27450, train_loss 29.041584014892578
eval_loss: 36.69179916381836 psnr: 33.44053268432617
iter 27500, train_loss 34.02116012573242
eval_loss: 36.008724212646484 psnr: 33.54782485961914
iter 27550, train_loss 32.73165512084961
eval_loss: 36.22654724121094 psnr: 33.512603759765625
iter 27600, train_loss 38.72685623168945
eval_loss: 35.235145568847656 psnr: 33.589046478271484
iter 27650, train_loss 30.24005126953125
eval_loss: 35.95096206665039 psnr: 33.52863693237305
iter 27700, train_loss 30.812597274780273
eval_loss: 35.58319854736328 psnr: 33.596832275390625
iter 27750, train_loss 34.59913635253906
eval_loss: 36.97223663330078 psnr: 33.448062896728516
iter 27800, train_loss 31.1446475982666
eval_loss: 35.61016845703125 psnr: 33.51620864868164
iter 27850, train_loss 37.13871383666992
eval_loss: 36.56892776489258 psnr: 33.49232482910156
iter 27900, train_loss 33.02522659301758
eval_loss: 34.908329010009766 psnr: 33.61695098876953
iter 27950, train_loss 33.56098175048828
eval_loss: 34.948795318603516 psnr: 33.702022552490234
iter 28000, train_loss 35.59478759765625
eval_loss: 35.191951751708984 psnr: 33.60212707519531
iter 28050, train_loss 29.862640380859375
eval_loss: 35.547325134277344 psnr: 33.57110595703125
iter 28100, train_loss 30.364089965820312
eval_loss: 36.336814880371094 psnr: 33.529151916503906
iter 28150, train_loss 29.587055206298828
eval_loss: 35.51362991333008 psnr: 33.55209732055664
iter 28200, train_loss 32.98228073120117
eval_loss: 36.189910888671875 psnr: 33.52089309692383
iter 28250, train_loss 34.192928314208984
eval_loss: 36.13365173339844 psnr: 33.5256462097168
iter 28300, train_loss 32.598731994628906
eval_loss: 34.555686950683594 psnr: 33.70292282104492
iter 28350, train_loss 29.18486976623535
eval_loss: 35.87413787841797 psnr: 33.57514572143555
iter 28400, train_loss 34.3474235534668
eval_loss: 34.79738998413086 psnr: 33.7342529296875
iter 28450, train_loss 34.347110748291016
eval_loss: 34.331295013427734 psnr: 33.70351028442383
iter 28500, train_loss 34.519107818603516
eval_loss: 36.00861358642578 psnr: 33.56600570678711
iter 28550, train_loss 32.371089935302734
eval_loss: 34.99142837524414 psnr: 33.75086212158203
iter 28600, train_loss 25.486005783081055
eval_loss: 35.28623580932617 psnr: 33.58837890625
iter 28650, train_loss 35.658023834228516
eval_loss: 35.08224868774414 psnr: 33.69432830810547
iter 28700, train_loss 28.634387969970703
eval_loss: 34.176597595214844 psnr: 33.86549758911133
iter 28750, train_loss 30.3284912109375
eval_loss: 33.73983383178711 psnr: 33.8064079284668
iter 28800, train_loss 29.640695571899414
eval_loss: 33.95403289794922 psnr: 33.83303451538086
iter 28850, train_loss 31.733810424804688
eval_loss: 35.34397888183594 psnr: 33.583377838134766
iter 28900, train_loss 30.114307403564453
eval_loss: 34.021568298339844 psnr: 33.80574035644531
iter 28950, train_loss 30.1768741607666
eval_loss: 34.896305084228516 psnr: 33.722076416015625
iter 29000, train_loss 25.389041900634766
eval_loss: 33.875526428222656 psnr: 33.82070541381836
iter 29050, train_loss 27.84085464477539
eval_loss: 33.74764633178711 psnr: 33.891357421875
iter 29100, train_loss 30.064123153686523
eval_loss: 33.854637145996094 psnr: 33.81979751586914
iter 29150, train_loss 27.193784713745117
eval_loss: 34.59200668334961 psnr: 33.75557327270508
iter 29200, train_loss 29.214313507080078
eval_loss: 33.45217514038086 psnr: 33.81826400756836
iter 29250, train_loss 28.22503662109375
eval_loss: 33.66624450683594 psnr: 33.836334228515625
iter 29300, train_loss 34.36606216430664
eval_loss: 35.07398986816406 psnr: 33.75175476074219
iter 29350, train_loss 27.63860511779785
eval_loss: 33.66252136230469 psnr: 33.879268646240234
iter 29400, train_loss 29.126569747924805
eval_loss: 32.811092376708984 psnr: 33.99022674560547
iter 29450, train_loss 28.242313385009766
eval_loss: 32.868282318115234 psnr: 33.9445915222168
iter 29500, train_loss 26.96241569519043
eval_loss: 34.07797622680664 psnr: 33.797061920166016
iter 29550, train_loss 26.975431442260742
eval_loss: 32.9880256652832 psnr: 33.981597900390625
iter 29600, train_loss 28.62298583984375
eval_loss: 33.32642364501953 psnr: 33.855445861816406
iter 29650, train_loss 31.873849868774414
eval_loss: 33.56635665893555 psnr: 33.897300720214844
iter 29700, train_loss 31.02911376953125
eval_loss: 34.407569885253906 psnr: 33.75505447387695
iter 29750, train_loss 28.23823356628418
eval_loss: 32.645263671875 psnr: 33.97501754760742
iter 29800, train_loss 31.233856201171875
eval_loss: 32.758724212646484 psnr: 34.00830841064453
iter 29850, train_loss 27.4415340423584
eval_loss: 32.48196029663086 psnr: 33.98453903198242
iter 29900, train_loss 33.359493255615234
eval_loss: 32.382564544677734 psnr: 34.03541564941406
iter 29950, train_loss 28.4326229095459
eval_loss: 33.50450134277344 psnr: 33.91180419921875
iter 30000, train_loss 28.038314819335938
eval_loss: 32.42516326904297 psnr: 34.00412368774414
iter 30050, train_loss 28.9841365814209
eval_loss: 33.329185485839844 psnr: 33.88930130004883
iter 30100, train_loss 28.015024185180664
eval_loss: 32.57802200317383 psnr: 34.005306243896484
iter 30150, train_loss 27.973791122436523
eval_loss: 32.22570037841797 psnr: 34.0590934753418
iter 30200, train_loss 30.09807777404785
eval_loss: 32.23899841308594 psnr: 34.09646224975586
iter 30250, train_loss 27.203723907470703
eval_loss: 32.73028564453125 psnr: 34.03346633911133
iter 30300, train_loss 31.530975341796875
eval_loss: 32.620697021484375 psnr: 33.945587158203125
iter 30350, train_loss 27.04868507385254
eval_loss: 32.34584045410156 psnr: 33.97645568847656
iter 30400, train_loss 28.727262496948242
eval_loss: 31.857837677001953 psnr: 34.110130310058594
iter 30450, train_loss 28.126800537109375
eval_loss: 32.8924560546875 psnr: 33.90254211425781
iter 30500, train_loss 26.327600479125977
eval_loss: 32.25342559814453 psnr: 33.98421859741211
iter 30550, train_loss 25.915130615234375
eval_loss: 31.855876922607422 psnr: 34.0635986328125
iter 30600, train_loss 29.754804611206055
eval_loss: 33.494773864746094 psnr: 33.928096771240234
iter 30650, train_loss 24.193370819091797
eval_loss: 31.967878341674805 psnr: 34.092472076416016
iter 30700, train_loss 28.508169174194336
eval_loss: 32.61980056762695 psnr: 33.922733306884766
iter 30750, train_loss 33.666038513183594
eval_loss: 32.293575286865234 psnr: 34.04862976074219
iter 30800, train_loss 27.12845802307129
eval_loss: 32.61976623535156 psnr: 34.1220588684082
iter 30850, train_loss 26.233734130859375
eval_loss: 32.81657409667969 psnr: 33.900699615478516
iter 30900, train_loss 26.864688873291016
eval_loss: 31.507314682006836 psnr: 34.14217758178711
iter 30950, train_loss 25.7131290435791
eval_loss: 31.301963806152344 psnr: 34.178443908691406
iter 31000, train_loss 32.632781982421875
eval_loss: 32.418128967285156 psnr: 34.05455780029297
iter 31050, train_loss 27.198938369750977
eval_loss: 32.0831184387207 psnr: 34.143104553222656
iter 31100, train_loss 30.669086456298828
eval_loss: 31.802417755126953 psnr: 34.040035247802734
iter 31150, train_loss 26.92685317993164
eval_loss: 31.64055824279785 psnr: 34.159236907958984
iter 31200, train_loss 27.761423110961914
eval_loss: 31.110313415527344 psnr: 34.20637512207031
iter 31250, train_loss 27.294965744018555
eval_loss: 31.846935272216797 psnr: 34.1003303527832
iter 31300, train_loss 26.522993087768555
eval_loss: 32.54387283325195 psnr: 34.039581298828125
iter 31350, train_loss 26.2597713470459
eval_loss: 32.69325637817383 psnr: 34.03440856933594
iter 31400, train_loss 23.863882064819336
eval_loss: 31.230281829833984 psnr: 34.11314392089844
iter 31450, train_loss 31.951812744140625
eval_loss: 31.829723358154297 psnr: 34.1485481262207
iter 31500, train_loss 26.520801544189453
eval_loss: 31.331642150878906 psnr: 34.15181350708008
iter 31550, train_loss 25.536609649658203
eval_loss: 31.610004425048828 psnr: 34.171531677246094
iter 31600, train_loss 25.44673728942871
eval_loss: 30.751766204833984 psnr: 34.240875244140625
iter 31650, train_loss 27.616342544555664
eval_loss: 31.345226287841797 psnr: 34.1896858215332
iter 31700, train_loss 26.77239990234375
eval_loss: 31.010086059570312 psnr: 34.222206115722656
iter 31750, train_loss 30.561328887939453
eval_loss: 30.589534759521484 psnr: 34.2542724609375
iter 31800, train_loss 26.232868194580078
eval_loss: 31.044816970825195 psnr: 34.186458587646484
iter 31850, train_loss 26.93878173828125
eval_loss: 31.121129989624023 psnr: 34.18838119506836
iter 31900, train_loss 29.671375274658203
eval_loss: 30.9818172454834 psnr: 34.231605529785156
iter 31950, train_loss 24.703523635864258
eval_loss: 31.940805435180664 psnr: 34.05717849731445
iter 32000, train_loss 27.585317611694336
eval_loss: 31.95557975769043 psnr: 34.11891555786133
iter 32050, train_loss 26.79153823852539
eval_loss: 30.156818389892578 psnr: 34.28840637207031
iter 32100, train_loss 27.3729305267334
eval_loss: 33.2056884765625 psnr: 34.00285720825195
iter 32150, train_loss 27.824872970581055
eval_loss: 30.21893882751465 psnr: 34.318153381347656
iter 32200, train_loss 24.262542724609375
eval_loss: 29.779394149780273 psnr: 34.449398040771484
iter 32250, train_loss 28.89580726623535
eval_loss: 30.131736755371094 psnr: 34.312583923339844
iter 32300, train_loss 27.27863121032715
eval_loss: 30.772119522094727 psnr: 34.24317932128906
iter 32350, train_loss 26.486135482788086
eval_loss: 31.36466407775879 psnr: 34.156551361083984
iter 32400, train_loss 27.214902877807617
eval_loss: 30.130271911621094 psnr: 34.347145080566406
iter 32450, train_loss 25.877716064453125
eval_loss: 30.24451446533203 psnr: 34.33024597167969
iter 32500, train_loss 26.287302017211914
eval_loss: 30.501873016357422 psnr: 34.19865798950195
iter 32550, train_loss 26.370025634765625
eval_loss: 30.279996871948242 psnr: 34.32147216796875
iter 32600, train_loss 25.874231338500977
eval_loss: 30.577056884765625 psnr: 34.26327133178711
iter 32650, train_loss 25.690134048461914
eval_loss: 29.938507080078125 psnr: 34.39008712768555
iter 32700, train_loss 25.180112838745117
eval_loss: 29.974483489990234 psnr: 34.383331298828125
iter 32750, train_loss 28.777545928955078
eval_loss: 30.10626792907715 psnr: 34.30190658569336
iter 32800, train_loss 25.289295196533203
eval_loss: 30.769275665283203 psnr: 34.2000732421875
iter 32850, train_loss 26.561416625976562
eval_loss: 30.54550552368164 psnr: 34.270774841308594
iter 32900, train_loss 25.07420539855957
eval_loss: 29.937129974365234 psnr: 34.354026794433594
iter 32950, train_loss 24.69187355041504
eval_loss: 29.941307067871094 psnr: 34.406314849853516
iter 33000, train_loss 28.419721603393555
eval_loss: 31.96888542175293 psnr: 34.25934600830078
iter 33050, train_loss 21.827590942382812
eval_loss: 29.905160903930664 psnr: 34.387691497802734
iter 33100, train_loss 21.671424865722656
eval_loss: 29.41600227355957 psnr: 34.390018463134766
iter 33150, train_loss 22.684316635131836
eval_loss: 28.880287170410156 psnr: 34.56879425048828
iter 33200, train_loss 27.119916915893555
eval_loss: 30.66338539123535 psnr: 34.334007263183594
iter 33250, train_loss 27.445545196533203
eval_loss: 29.16860580444336 psnr: 34.52157974243164
iter 33300, train_loss 24.62555503845215
eval_loss: 29.381078720092773 psnr: 34.4756965637207
iter 33350, train_loss 27.308002471923828
eval_loss: 30.315412521362305 psnr: 34.3787727355957
iter 33400, train_loss 29.694543838500977
eval_loss: 30.302696228027344 psnr: 34.37586975097656
iter 33450, train_loss 26.56536865234375
eval_loss: 29.234472274780273 psnr: 34.46738052368164
iter 33500, train_loss 25.10243034362793
eval_loss: 30.218887329101562 psnr: 34.37997055053711
iter 33550, train_loss 25.85980224609375
eval_loss: 29.5318603515625 psnr: 34.42430877685547
iter 33600, train_loss 28.027008056640625
eval_loss: 30.55118179321289 psnr: 34.32260513305664
iter 33650, train_loss 20.62114715576172
eval_loss: 28.9666748046875 psnr: 34.461891174316406
iter 33700, train_loss 27.054895401000977
eval_loss: 28.59605598449707 psnr: 34.518428802490234
iter 33750, train_loss 26.59995460510254
eval_loss: 29.628433227539062 psnr: 34.49739074707031
iter 33800, train_loss 27.171890258789062
eval_loss: 29.677234649658203 psnr: 34.390174865722656
iter 33850, train_loss 28.73541259765625
eval_loss: 29.769060134887695 psnr: 34.39680099487305
iter 33900, train_loss 27.71868324279785
eval_loss: 29.282949447631836 psnr: 34.48778533935547
iter 33950, train_loss 20.371946334838867
eval_loss: 29.087705612182617 psnr: 34.510677337646484
iter 34000, train_loss 22.381555557250977
eval_loss: 29.336166381835938 psnr: 34.50524139404297
iter 34050, train_loss 23.56918716430664
eval_loss: 29.153820037841797 psnr: 34.55606460571289
iter 34100, train_loss 22.897546768188477
eval_loss: 29.060392379760742 psnr: 34.47410583496094
iter 34150, train_loss 20.91019058227539
eval_loss: 28.86438751220703 psnr: 34.594879150390625
iter 34200, train_loss 27.065067291259766
eval_loss: 28.586124420166016 psnr: 34.672977447509766
iter 34250, train_loss 27.489500045776367
eval_loss: 29.299386978149414 psnr: 34.50096130371094
iter 34300, train_loss 25.043664932250977
eval_loss: 28.676029205322266 psnr: 34.4705924987793
iter 34350, train_loss 26.004032135009766
eval_loss: 30.196443557739258 psnr: 34.37917709350586
iter 34400, train_loss 24.25904655456543
eval_loss: 28.85805320739746 psnr: 34.52741622924805
iter 34450, train_loss 22.115055084228516
eval_loss: 28.36066246032715 psnr: 34.57435607910156
iter 34500, train_loss 22.472562789916992
eval_loss: 29.017009735107422 psnr: 34.50432205200195
iter 34550, train_loss 27.957136154174805
eval_loss: 29.208017349243164 psnr: 34.51999282836914
iter 34600, train_loss 25.21082878112793
eval_loss: 28.745941162109375 psnr: 34.574859619140625
iter 34650, train_loss 24.32655143737793
eval_loss: 28.549541473388672 psnr: 34.58230209350586
iter 34700, train_loss 24.61957359313965
eval_loss: 28.923250198364258 psnr: 34.611793518066406
iter 34750, train_loss 24.00871467590332
eval_loss: 29.022809982299805 psnr: 34.56026840209961
iter 34800, train_loss 26.146682739257812
eval_loss: 29.224342346191406 psnr: 34.517677307128906
iter 34850, train_loss 25.097827911376953
eval_loss: 29.75243377685547 psnr: 34.49755859375
iter 34900, train_loss 23.895788192749023
eval_loss: 28.233579635620117 psnr: 34.68642044067383
iter 34950, train_loss 22.798168182373047
eval_loss: 28.267902374267578 psnr: 34.62031555175781
iter 35000, train_loss 26.567127227783203
eval_loss: 28.494216918945312 psnr: 34.58900451660156
iter 35050, train_loss 22.90945816040039
eval_loss: 28.00731086730957 psnr: 34.67729949951172
iter 35100, train_loss 24.463260650634766
eval_loss: 28.954509735107422 psnr: 34.515926361083984
iter 35150, train_loss 21.727914810180664
eval_loss: 27.308338165283203 psnr: 34.806922912597656
iter 35200, train_loss 21.99568748474121
eval_loss: 27.757490158081055 psnr: 34.69945526123047
iter 35250, train_loss 26.30970573425293
eval_loss: 28.064212799072266 psnr: 34.61863327026367
iter 35300, train_loss 27.474624633789062
eval_loss: 28.525760650634766 psnr: 34.57221221923828
iter 35350, train_loss 26.28419303894043
eval_loss: 29.055461883544922 psnr: 34.42336654663086
iter 35400, train_loss 22.87702751159668
eval_loss: 27.769929885864258 psnr: 34.66879653930664
iter 35450, train_loss 22.352493286132812
eval_loss: 27.274059295654297 psnr: 34.82821273803711
iter 35500, train_loss 20.653106689453125
eval_loss: 27.745216369628906 psnr: 34.74275207519531
iter 35550, train_loss 27.14943504333496
eval_loss: 28.833759307861328 psnr: 34.63092803955078
iter 35600, train_loss 25.656482696533203
eval_loss: 28.09746551513672 psnr: 34.73788070678711
iter 35650, train_loss 23.79091453552246
eval_loss: 27.438024520874023 psnr: 34.742149353027344
iter 35700, train_loss 22.689376831054688
eval_loss: 27.66785430908203 psnr: 34.736968994140625
iter 35750, train_loss 21.531166076660156
eval_loss: 27.75922393798828 psnr: 34.745235443115234
iter 35800, train_loss 24.395593643188477
eval_loss: 28.18777847290039 psnr: 34.639286041259766
iter 35850, train_loss 19.631811141967773
eval_loss: 27.007848739624023 psnr: 34.83294677734375
iter 35900, train_loss 24.81844139099121
eval_loss: 27.606985092163086 psnr: 34.7725944519043
iter 35950, train_loss 23.73569107055664
eval_loss: 27.850351333618164 psnr: 34.62813186645508
iter 36000, train_loss 21.5761775970459
eval_loss: 27.601377487182617 psnr: 34.74531555175781
iter 36050, train_loss 21.694459915161133
eval_loss: 27.994733810424805 psnr: 34.65348815917969
iter 36100, train_loss 26.256906509399414
eval_loss: 27.829952239990234 psnr: 34.6450309753418
iter 36150, train_loss 23.055551528930664
eval_loss: 27.29415512084961 psnr: 34.85045623779297
iter 36200, train_loss 24.538572311401367
eval_loss: 28.399139404296875 psnr: 34.59292984008789
iter 36250, train_loss 25.984420776367188
eval_loss: 26.924795150756836 psnr: 34.771114349365234
iter 36300, train_loss 24.701251983642578
eval_loss: 27.25918197631836 psnr: 34.80873489379883
iter 36350, train_loss 27.491941452026367
eval_loss: 29.55515480041504 psnr: 34.620033264160156
iter 36400, train_loss 27.913532257080078
eval_loss: 29.132492065429688 psnr: 34.523372650146484
iter 36450, train_loss 20.662473678588867
eval_loss: 26.30178451538086 psnr: 34.95970153808594
iter 36500, train_loss 20.334041595458984
eval_loss: 27.997854232788086 psnr: 34.715152740478516
iter 36550, train_loss 26.874032974243164
eval_loss: 28.246356964111328 psnr: 34.71839141845703
iter 36600, train_loss 24.078166961669922
eval_loss: 27.78111457824707 psnr: 34.73503494262695
iter 36650, train_loss 24.832868576049805
eval_loss: 26.970556259155273 psnr: 34.82487106323242
iter 36700, train_loss 21.967374801635742
eval_loss: 27.02528190612793 psnr: 34.80904769897461
iter 36750, train_loss 23.031448364257812
eval_loss: 27.472749710083008 psnr: 34.8117561340332
iter 36800, train_loss 19.952651977539062
eval_loss: 27.02237892150879 psnr: 34.85032653808594
iter 36850, train_loss 20.48209571838379
eval_loss: 27.360803604125977 psnr: 34.77552795410156
iter 36900, train_loss 26.822477340698242
eval_loss: 27.45906639099121 psnr: 34.789432525634766
iter 36950, train_loss 25.52522850036621
eval_loss: 27.70038604736328 psnr: 34.77667999267578
iter 37000, train_loss 25.379785537719727
eval_loss: 26.43708038330078 psnr: 34.923240661621094
iter 37050, train_loss 21.769838333129883
eval_loss: 27.12346649169922 psnr: 34.83638381958008
iter 37100, train_loss 21.075504302978516
eval_loss: 27.756986618041992 psnr: 34.773841857910156
iter 37150, train_loss 22.382246017456055
eval_loss: 26.260913848876953 psnr: 34.96296691894531
iter 37200, train_loss 24.431772232055664
eval_loss: 27.042171478271484 psnr: 34.81960678100586
iter 37250, train_loss 25.406543731689453
eval_loss: 27.633785247802734 psnr: 34.82053756713867
iter 37300, train_loss 25.79786491394043
eval_loss: 27.077836990356445 psnr: 34.82992172241211
iter 37350, train_loss 22.078399658203125
eval_loss: 26.151321411132812 psnr: 34.93938064575195
iter 37400, train_loss 22.165027618408203
eval_loss: 25.931791305541992 psnr: 35.05014419555664
iter 37450, train_loss 17.891300201416016
eval_loss: 26.55352020263672 psnr: 34.95802688598633
iter 37500, train_loss 23.44000244140625
eval_loss: 25.871057510375977 psnr: 35.07480239868164
iter 37550, train_loss 25.5853214263916
eval_loss: 26.523990631103516 psnr: 34.966217041015625
iter 37600, train_loss 23.005218505859375
eval_loss: 27.462871551513672 psnr: 34.766578674316406
iter 37650, train_loss 23.359067916870117
eval_loss: 26.039165496826172 psnr: 35.04967498779297
iter 37700, train_loss 19.610204696655273
eval_loss: 27.244407653808594 psnr: 34.86625289916992
iter 37750, train_loss 22.835201263427734
eval_loss: 26.67875862121582 psnr: 34.93132019042969
iter 37800, train_loss 21.57644271850586
eval_loss: 26.86929702758789 psnr: 34.863868713378906
iter 37850, train_loss 25.872556686401367
eval_loss: 26.22479248046875 psnr: 35.01811218261719
iter 37900, train_loss 19.233657836914062
eval_loss: 25.886611938476562 psnr: 35.047760009765625
iter 37950, train_loss 23.128469467163086
eval_loss: 26.54079246520996 psnr: 34.91472625732422
iter 38000, train_loss 20.139001846313477
eval_loss: 27.443859100341797 psnr: 34.74235153198242
iter 38050, train_loss 23.663698196411133
eval_loss: 26.080015182495117 psnr: 35.031639099121094
iter 38100, train_loss 20.948694229125977
eval_loss: 26.45281219482422 psnr: 34.95991134643555
iter 38150, train_loss 18.233501434326172
eval_loss: 25.601852416992188 psnr: 35.09528350830078
iter 38200, train_loss 20.619043350219727
eval_loss: 25.756441116333008 psnr: 35.03287887573242
iter 38250, train_loss 27.51803970336914
eval_loss: 28.848499298095703 psnr: 34.4984130859375
iter 38300, train_loss 23.29568099975586
eval_loss: 26.589136123657227 psnr: 34.89774703979492
iter 38350, train_loss 20.688392639160156
eval_loss: 25.751691818237305 psnr: 35.083927154541016
iter 38400, train_loss 20.79170036315918
eval_loss: 26.086986541748047 psnr: 34.97422409057617
iter 38450, train_loss 23.291112899780273
eval_loss: 25.730632781982422 psnr: 35.12478256225586
iter 38500, train_loss 22.254209518432617
eval_loss: 25.957630157470703 psnr: 34.99695587158203
iter 38550, train_loss 24.016008377075195
eval_loss: 26.658946990966797 psnr: 34.97140884399414
iter 38600, train_loss 21.842071533203125
eval_loss: 26.20878791809082 psnr: 34.98597717285156
iter 38650, train_loss 26.16383171081543
eval_loss: 27.45539665222168 psnr: 34.74055862426758
iter 38700, train_loss 23.651931762695312
eval_loss: 26.713472366333008 psnr: 34.95647048950195
iter 38750, train_loss 24.24880599975586
eval_loss: 25.651838302612305 psnr: 35.073551177978516
iter 38800, train_loss 21.969444274902344
eval_loss: 25.75031280517578 psnr: 34.96278381347656
iter 38850, train_loss 22.810272216796875
eval_loss: 25.874011993408203 psnr: 35.042579650878906
iter 38900, train_loss 21.998090744018555
eval_loss: 26.880123138427734 psnr: 34.87271499633789
iter 38950, train_loss 21.05865478515625
eval_loss: 25.557186126708984 psnr: 35.07548904418945
iter 39000, train_loss 19.33735466003418
eval_loss: 24.806943893432617 psnr: 35.268882751464844
iter 39050, train_loss 22.332117080688477
eval_loss: 26.66087532043457 psnr: 34.91385269165039
iter 39100, train_loss 18.075809478759766
eval_loss: 25.93735694885254 psnr: 35.03330612182617
iter 39150, train_loss 21.099267959594727
eval_loss: 25.406784057617188 psnr: 35.02248001098633
iter 39200, train_loss 22.57143783569336
eval_loss: 26.437116622924805 psnr: 34.856201171875
iter 39250, train_loss 20.192626953125
eval_loss: 26.36191177368164 psnr: 34.944210052490234
iter 39300, train_loss 21.489986419677734
eval_loss: 25.62892723083496 psnr: 35.041664123535156
iter 39350, train_loss 21.780065536499023
eval_loss: 25.604103088378906 psnr: 35.09019088745117
iter 39400, train_loss 25.16516876220703
eval_loss: 27.286434173583984 psnr: 34.84962844848633
iter 39450, train_loss 21.110036849975586
eval_loss: 25.081310272216797 psnr: 35.152618408203125
iter 39500, train_loss 23.13019371032715
eval_loss: 26.780765533447266 psnr: 34.86914825439453
iter 39550, train_loss 20.802907943725586
eval_loss: 25.916845321655273 psnr: 34.997291564941406
iter 39600, train_loss 23.06682777404785
eval_loss: 25.265567779541016 psnr: 35.12071228027344
iter 39650, train_loss 20.46782684326172
eval_loss: 25.285629272460938 psnr: 35.154659271240234
iter 39700, train_loss 20.65777587890625
eval_loss: 24.975051879882812 psnr: 35.19834518432617
iter 39750, train_loss 24.054105758666992
eval_loss: 25.52768325805664 psnr: 35.11470031738281
iter 39800, train_loss 22.444936752319336
eval_loss: 27.19245719909668 psnr: 34.94881820678711
iter 39850, train_loss 20.638111114501953
eval_loss: 25.650392532348633 psnr: 35.17852020263672
iter 39900, train_loss 21.9539852142334
eval_loss: 24.94635772705078 psnr: 35.18109130859375
iter 39950, train_loss 22.17767333984375
eval_loss: 25.49740219116211 psnr: 35.03672409057617
iter 40000, train_loss 20.325834274291992
eval_loss: 25.285964965820312 psnr: 35.112003326416016
iter 40050, train_loss 21.83516502380371
eval_loss: 24.968326568603516 psnr: 35.11526107788086
iter 40100, train_loss 20.94418716430664
eval_loss: 24.665632247924805 psnr: 35.20254135131836
iter 40150, train_loss 21.406259536743164
eval_loss: 24.82010841369629 psnr: 35.279937744140625
iter 40200, train_loss 21.139341354370117
eval_loss: 25.655324935913086 psnr: 35.06291198730469
iter 40250, train_loss 22.245100021362305
eval_loss: 25.280927658081055 psnr: 35.17855453491211
iter 40300, train_loss 20.498655319213867
eval_loss: 24.969694137573242 psnr: 35.231231689453125
iter 40350, train_loss 20.228097915649414
eval_loss: 25.033411026000977 psnr: 35.219905853271484
iter 40400, train_loss 19.773908615112305
eval_loss: 24.984743118286133 psnr: 35.1884651184082
iter 40450, train_loss 22.673236846923828
eval_loss: 26.493257522583008 psnr: 35.04362106323242
iter 40500, train_loss 20.862062454223633
eval_loss: 26.182180404663086 psnr: 35.073692321777344
iter 40550, train_loss 24.557931900024414
eval_loss: 27.260377883911133 psnr: 34.814571380615234
iter 40600, train_loss 19.463668823242188
eval_loss: 24.74019432067871 psnr: 35.24004364013672
iter 40650, train_loss 21.6319580078125
eval_loss: 24.905813217163086 psnr: 35.14553451538086
iter 40700, train_loss 21.3404541015625
eval_loss: 25.358911514282227 psnr: 35.15049362182617
iter 40750, train_loss 23.894161224365234
eval_loss: 24.53204345703125 psnr: 35.194000244140625
iter 40800, train_loss 21.407257080078125
eval_loss: 25.681232452392578 psnr: 35.07123947143555
iter 40850, train_loss 21.4736385345459
eval_loss: 25.36618995666504 psnr: 35.090675354003906
iter 40900, train_loss 19.404781341552734
eval_loss: 24.56387710571289 psnr: 35.286888122558594
iter 40950, train_loss 25.466339111328125
eval_loss: 25.655906677246094 psnr: 35.14512634277344
iter 41000, train_loss 18.557008743286133
eval_loss: 24.61939239501953 psnr: 35.276031494140625
iter 41050, train_loss 20.866317749023438
eval_loss: 25.6513729095459 psnr: 35.07898712158203
iter 41100, train_loss 20.480587005615234
eval_loss: 24.308265686035156 psnr: 35.34052276611328
iter 41150, train_loss 18.992212295532227
eval_loss: 25.09271812438965 psnr: 35.155311584472656
iter 41200, train_loss 19.719100952148438
eval_loss: 24.19771957397461 psnr: 35.38596725463867
iter 41250, train_loss 17.59636116027832
eval_loss: 25.231708526611328 psnr: 35.10515213012695
iter 41300, train_loss 21.094223022460938
eval_loss: 24.974905014038086 psnr: 35.214195251464844
iter 41350, train_loss 22.919065475463867
eval_loss: 24.8724422454834 psnr: 35.231075286865234
iter 41400, train_loss 19.999927520751953
eval_loss: 24.762407302856445 psnr: 35.261260986328125
iter 41450, train_loss 20.937942504882812
eval_loss: 25.094430923461914 psnr: 35.206260681152344
iter 41500, train_loss 19.378995895385742
eval_loss: 25.485891342163086 psnr: 35.12495803833008
iter 41550, train_loss 22.102243423461914
eval_loss: 24.1178035736084 psnr: 35.36389923095703
iter 41600, train_loss 18.18065071105957
eval_loss: 24.191852569580078 psnr: 35.222225189208984
iter 41650, train_loss 20.606678009033203
eval_loss: 24.637117385864258 psnr: 35.297428131103516
iter 41700, train_loss 22.590408325195312
eval_loss: 24.499351501464844 psnr: 35.2943000793457
iter 41750, train_loss 22.727190017700195
eval_loss: 24.472248077392578 psnr: 35.25540542602539
iter 41800, train_loss 22.31551170349121
eval_loss: 26.092910766601562 psnr: 35.028350830078125
iter 41850, train_loss 20.079721450805664
eval_loss: 24.810420989990234 psnr: 35.2557487487793
iter 41900, train_loss 17.911375045776367
eval_loss: 23.794042587280273 psnr: 35.43859100341797
iter 41950, train_loss 18.629438400268555
eval_loss: 24.9169921875 psnr: 35.217159271240234
iter 42000, train_loss 19.5111026763916
eval_loss: 24.644235610961914 psnr: 35.33013153076172
iter 42050, train_loss 22.359045028686523
eval_loss: 24.963802337646484 psnr: 35.23402404785156
iter 42100, train_loss 17.351041793823242
eval_loss: 24.142847061157227 psnr: 35.434715270996094
iter 42150, train_loss 21.933279037475586
eval_loss: 25.20720100402832 psnr: 35.18486404418945
iter 42200, train_loss 23.186059951782227
eval_loss: 24.268909454345703 psnr: 35.280033111572266
iter 42250, train_loss 17.88014030456543
eval_loss: 24.02379035949707 psnr: 35.35064697265625
iter 42300, train_loss 21.337522506713867
eval_loss: 24.267780303955078 psnr: 35.32656478881836
iter 42350, train_loss 23.226537704467773
eval_loss: 24.482027053833008 psnr: 35.32672119140625
iter 42400, train_loss 19.484403610229492
eval_loss: 24.446277618408203 psnr: 35.279415130615234
iter 42450, train_loss 20.681398391723633
eval_loss: 24.11526107788086 psnr: 35.40761947631836
iter 42500, train_loss 20.248737335205078
eval_loss: 25.689037322998047 psnr: 35.175052642822266
iter 42550, train_loss 20.589920043945312
eval_loss: 24.660259246826172 psnr: 35.28483581542969
iter 42600, train_loss 19.306821823120117
eval_loss: 25.102373123168945 psnr: 35.17068862915039
iter 42650, train_loss 20.37688446044922
eval_loss: 24.561534881591797 psnr: 35.22553634643555
iter 42700, train_loss 17.539358139038086
eval_loss: 23.923320770263672 psnr: 35.41481399536133
iter 42750, train_loss 21.588911056518555
eval_loss: 24.186336517333984 psnr: 35.30923843383789
iter 42800, train_loss 19.651947021484375
eval_loss: 24.2219181060791 psnr: 35.37442398071289
iter 42850, train_loss 19.577085494995117
eval_loss: 24.389877319335938 psnr: 35.31829071044922
iter 42900, train_loss 19.080251693725586
eval_loss: 24.682798385620117 psnr: 35.16237258911133
iter 42950, train_loss 22.111326217651367
eval_loss: 23.996835708618164 psnr: 35.35074234008789
iter 43000, train_loss 17.998111724853516
eval_loss: 24.143978118896484 psnr: 35.31359100341797
iter 43050, train_loss 19.295135498046875
eval_loss: 24.609619140625 psnr: 35.27080535888672
iter 43100, train_loss 20.048086166381836
eval_loss: 25.33067512512207 psnr: 35.09370803833008
iter 43150, train_loss 17.096731185913086
eval_loss: 23.573482513427734 psnr: 35.429203033447266
iter 43200, train_loss 17.085599899291992
eval_loss: 24.759004592895508 psnr: 35.228878021240234
iter 43250, train_loss 22.383710861206055
eval_loss: 24.282541275024414 psnr: 35.30479431152344
iter 43300, train_loss 20.22235679626465
eval_loss: 24.097393035888672 psnr: 35.372013092041016
iter 43350, train_loss 17.119647979736328
eval_loss: 23.87212562561035 psnr: 35.39685821533203
iter 43400, train_loss 20.504751205444336
eval_loss: 23.966602325439453 psnr: 35.416175842285156
iter 43450, train_loss 20.291873931884766
eval_loss: 23.936918258666992 psnr: 35.37958908081055
iter 43500, train_loss 20.155149459838867
eval_loss: 25.00217056274414 psnr: 35.132347106933594
iter 43550, train_loss 18.237503051757812
eval_loss: 23.970863342285156 psnr: 35.400726318359375
iter 43600, train_loss 19.252826690673828
eval_loss: 23.892507553100586 psnr: 35.3929557800293
iter 43650, train_loss 19.51129722595215
eval_loss: 23.431318283081055 psnr: 35.46746063232422
iter 43700, train_loss 20.39789390563965
eval_loss: 24.363445281982422 psnr: 35.313934326171875
iter 43750, train_loss 20.35667610168457
eval_loss: 24.041156768798828 psnr: 35.35408401489258
iter 43800, train_loss 20.69338035583496
eval_loss: 24.32288360595703 psnr: 35.33081817626953
iter 43850, train_loss 20.09589195251465
eval_loss: 24.24024772644043 psnr: 35.378326416015625
iter 43900, train_loss 20.25946807861328
eval_loss: 24.315635681152344 psnr: 35.31852722167969
iter 43950, train_loss 18.84480094909668
eval_loss: 23.89285659790039 psnr: 35.350521087646484
iter 44000, train_loss 19.75978660583496
eval_loss: 23.378149032592773 psnr: 35.512786865234375
iter 44050, train_loss 18.90130615234375
eval_loss: 23.568336486816406 psnr: 35.44234085083008
iter 44100, train_loss 21.455442428588867
eval_loss: 23.79323387145996 psnr: 35.3741455078125
iter 44150, train_loss 19.263263702392578
eval_loss: 22.980810165405273 psnr: 35.588043212890625
iter 44200, train_loss 20.123916625976562
eval_loss: 23.77291488647461 psnr: 35.3531379699707
iter 44250, train_loss 17.409074783325195
eval_loss: 23.97580337524414 psnr: 35.428466796875
iter 44300, train_loss 23.450714111328125
eval_loss: 23.896961212158203 psnr: 35.37923812866211
iter 44350, train_loss 18.245222091674805
eval_loss: 23.057205200195312 psnr: 35.601585388183594
iter 44400, train_loss 17.241653442382812
eval_loss: 23.679502487182617 psnr: 35.448455810546875
iter 44450, train_loss 20.849899291992188
eval_loss: 23.475008010864258 psnr: 35.3594856262207
iter 44500, train_loss 19.67717933654785
eval_loss: 23.877628326416016 psnr: 35.386451721191406
iter 44550, train_loss 20.424131393432617
eval_loss: 23.32072639465332 psnr: 35.617332458496094
iter 44600, train_loss 19.942543029785156
eval_loss: 23.34748077392578 psnr: 35.51131057739258
iter 44650, train_loss 20.2249755859375
eval_loss: 23.35067367553711 psnr: 35.49732208251953
iter 44700, train_loss 20.257822036743164
eval_loss: 24.569156646728516 psnr: 35.24570846557617
iter 44750, train_loss 21.016313552856445
eval_loss: 24.01040267944336 psnr: 35.33653259277344
iter 44800, train_loss 20.610973358154297
eval_loss: 23.76816749572754 psnr: 35.377418518066406
iter 44850, train_loss 17.55917739868164
eval_loss: 23.943490982055664 psnr: 35.36317443847656
iter 44900, train_loss 18.524030685424805
eval_loss: 23.163570404052734 psnr: 35.49636459350586
iter 44950, train_loss 17.565168380737305
eval_loss: 22.849956512451172 psnr: 35.64497756958008
iter 45000, train_loss 16.59114646911621
eval_loss: 23.75037956237793 psnr: 35.44492721557617
iter 45050, train_loss 17.426076889038086
eval_loss: 23.330724716186523 psnr: 35.52861404418945
iter 45100, train_loss 19.13433837890625
eval_loss: 24.140499114990234 psnr: 35.250335693359375
iter 45150, train_loss 19.855632781982422
eval_loss: 23.12995147705078 psnr: 35.51068115234375
iter 45200, train_loss 16.5689754486084
eval_loss: 22.828916549682617 psnr: 35.617897033691406
iter 45250, train_loss 21.691091537475586
eval_loss: 22.976764678955078 psnr: 35.552146911621094
iter 45300, train_loss 21.646493911743164
eval_loss: 24.015594482421875 psnr: 35.372474670410156
iter 45350, train_loss 19.00244140625
eval_loss: 23.673288345336914 psnr: 35.44440841674805
iter 45400, train_loss 17.0535831451416
eval_loss: 24.820114135742188 psnr: 35.22293472290039
iter 45450, train_loss 16.11396026611328
eval_loss: 23.171655654907227 psnr: 35.53205108642578
iter 45500, train_loss 18.641754150390625
eval_loss: 23.113113403320312 psnr: 35.5554084777832
iter 45550, train_loss 21.646385192871094
eval_loss: 23.768688201904297 psnr: 35.56742477416992
iter 45600, train_loss 19.305917739868164
eval_loss: 23.50720977783203 psnr: 35.488037109375
iter 45650, train_loss 18.480321884155273
eval_loss: 22.837583541870117 psnr: 35.60688400268555
iter 45700, train_loss 19.4016170501709
eval_loss: 23.388378143310547 psnr: 35.550106048583984
iter 45750, train_loss 19.74419593811035
eval_loss: 22.58160400390625 psnr: 35.617462158203125
iter 45800, train_loss 21.5882625579834
eval_loss: 24.025632858276367 psnr: 35.359867095947266
iter 45850, train_loss 18.15488052368164
eval_loss: 22.616832733154297 psnr: 35.71281051635742
iter 45900, train_loss 18.956195831298828
eval_loss: 22.99864959716797 psnr: 35.55817794799805
iter 45950, train_loss 16.681915283203125
eval_loss: 23.420454025268555 psnr: 35.472938537597656
iter 46000, train_loss 20.152446746826172
eval_loss: 23.154388427734375 psnr: 35.53417205810547
iter 46050, train_loss 19.443164825439453
eval_loss: 24.641218185424805 psnr: 35.1990966796875
iter 46100, train_loss 21.011734008789062
eval_loss: 23.907642364501953 psnr: 35.449092864990234
iter 46150, train_loss 17.603347778320312
eval_loss: 23.364051818847656 psnr: 35.45718765258789
iter 46200, train_loss 18.92082405090332
eval_loss: 22.8894100189209 psnr: 35.449607849121094
iter 46250, train_loss 16.54258155822754
eval_loss: 22.168153762817383 psnr: 35.75730514526367
iter 46300, train_loss 19.21424674987793
eval_loss: 23.417675018310547 psnr: 35.49714279174805
iter 46350, train_loss 18.3995361328125
eval_loss: 23.46506690979004 psnr: 35.44270324707031
iter 46400, train_loss 17.2908992767334
eval_loss: 22.99248504638672 psnr: 35.458045959472656
iter 46450, train_loss 16.835792541503906
eval_loss: 22.778644561767578 psnr: 35.639183044433594
iter 46500, train_loss 15.318252563476562
eval_loss: 22.666841506958008 psnr: 35.596004486083984
iter 46550, train_loss 17.18067741394043
eval_loss: 24.292383193969727 psnr: 35.36861038208008
iter 46600, train_loss 19.81009864807129
eval_loss: 23.088294982910156 psnr: 35.5467414855957
iter 46650, train_loss 17.80314064025879
eval_loss: 22.72536277770996 psnr: 35.59739685058594
iter 46700, train_loss 20.843137741088867
eval_loss: 23.44927978515625 psnr: 35.49246597290039
iter 46750, train_loss 16.98645782470703
eval_loss: 22.84902000427246 psnr: 35.61982345581055
iter 46800, train_loss 19.238393783569336
eval_loss: 23.29612159729004 psnr: 35.57122802734375
iter 46850, train_loss 19.626863479614258
eval_loss: 23.486087799072266 psnr: 35.53255844116211
iter 46900, train_loss 18.103132247924805
eval_loss: 22.940898895263672 psnr: 35.58877182006836
iter 46950, train_loss 18.139179229736328
eval_loss: 23.263395309448242 psnr: 35.514854431152344
iter 47000, train_loss 19.71392250061035
eval_loss: 23.4935245513916 psnr: 35.45161056518555
iter 47050, train_loss 19.50635528564453
eval_loss: 22.839523315429688 psnr: 35.537811279296875
iter 47100, train_loss 19.163183212280273
eval_loss: 22.864763259887695 psnr: 35.60218811035156
iter 47150, train_loss 17.365243911743164
eval_loss: 21.982370376586914 psnr: 35.729698181152344
iter 47200, train_loss 20.1868953704834
eval_loss: 23.429805755615234 psnr: 35.53816604614258
iter 47250, train_loss 17.560993194580078
eval_loss: 22.781173706054688 psnr: 35.5823974609375
iter 47300, train_loss 18.159000396728516
eval_loss: 22.871095657348633 psnr: 35.595375061035156
iter 47350, train_loss 18.498695373535156
eval_loss: 22.35235595703125 psnr: 35.724483489990234
iter 47400, train_loss 19.458494186401367
eval_loss: 22.344993591308594 psnr: 35.71101379394531
iter 47450, train_loss 19.206567764282227
eval_loss: 21.951799392700195 psnr: 35.770233154296875
iter 47500, train_loss 18.698469161987305
eval_loss: 22.408735275268555 psnr: 35.674705505371094
iter 47550, train_loss 19.099822998046875
eval_loss: 22.143688201904297 psnr: 35.76313018798828
iter 47600, train_loss 19.046417236328125
eval_loss: 22.37979507446289 psnr: 35.707950592041016
iter 47650, train_loss 16.893417358398438
eval_loss: 23.481334686279297 psnr: 35.418392181396484
iter 47700, train_loss 18.124494552612305
eval_loss: 22.786130905151367 psnr: 35.529945373535156
iter 47750, train_loss 17.20359992980957
eval_loss: 22.465087890625 psnr: 35.616241455078125
iter 47800, train_loss 18.990148544311523
eval_loss: 22.09763526916504 psnr: 35.667022705078125
iter 47850, train_loss 20.475820541381836
eval_loss: 22.59530258178711 psnr: 35.61035919189453
iter 47900, train_loss 19.300092697143555
eval_loss: 22.188127517700195 psnr: 35.61735153198242
iter 47950, train_loss 19.413297653198242
eval_loss: 23.173917770385742 psnr: 35.508174896240234
iter 48000, train_loss 17.998506546020508
eval_loss: 22.67902946472168 psnr: 35.661224365234375
iter 48050, train_loss 17.931486129760742
eval_loss: 22.034584045410156 psnr: 35.62725067138672
iter 48100, train_loss 19.105361938476562
eval_loss: 22.22117042541504 psnr: 35.69363021850586
iter 48150, train_loss 16.68404769897461
eval_loss: 22.821414947509766 psnr: 35.634368896484375
iter 48200, train_loss 17.56123924255371
eval_loss: 22.400394439697266 psnr: 35.696163177490234
iter 48250, train_loss 24.186424255371094
eval_loss: 23.860897064208984 psnr: 35.45134353637695
iter 48300, train_loss 20.859411239624023
eval_loss: 22.070261001586914 psnr: 35.734310150146484
iter 48350, train_loss 16.6591796875
eval_loss: 21.790300369262695 psnr: 35.76137161254883
iter 48400, train_loss 17.25356101989746
eval_loss: 22.817594528198242 psnr: 35.591468811035156
iter 48450, train_loss 19.962339401245117
eval_loss: 23.881874084472656 psnr: 35.365501403808594
iter 48500, train_loss 19.25251579284668
eval_loss: 22.56212615966797 psnr: 35.59013748168945
iter 48550, train_loss 17.2644100189209
eval_loss: 22.94966697692871 psnr: 35.58461380004883
iter 48600, train_loss 17.045154571533203
eval_loss: 22.489160537719727 psnr: 35.678749084472656
iter 48650, train_loss 17.10609245300293
eval_loss: 22.98423194885254 psnr: 35.5750846862793
iter 48700, train_loss 15.450268745422363
eval_loss: 21.604583740234375 psnr: 35.87180709838867
iter 48750, train_loss 18.351974487304688
eval_loss: 22.201370239257812 psnr: 35.75214385986328
iter 48800, train_loss 17.78407859802246
eval_loss: 22.439680099487305 psnr: 35.67289352416992
iter 48850, train_loss 18.853370666503906
eval_loss: 22.2189884185791 psnr: 35.67348861694336
iter 48900, train_loss 16.752775192260742
eval_loss: 21.394729614257812 psnr: 35.86410140991211
iter 48950, train_loss 17.404081344604492
eval_loss: 22.163694381713867 psnr: 35.66329574584961
iter 49000, train_loss 19.57313346862793
eval_loss: 24.31748390197754 psnr: 35.33271408081055
iter 49050, train_loss 20.962594985961914
eval_loss: 22.250003814697266 psnr: 35.68887710571289
iter 49100, train_loss 18.82166862487793
eval_loss: 21.2708797454834 psnr: 35.91301727294922
iter 49150, train_loss 18.097700119018555
eval_loss: 21.97159767150879 psnr: 35.770111083984375
iter 49200, train_loss 14.821812629699707
eval_loss: 21.955781936645508 psnr: 35.8014030456543
iter 49250, train_loss 17.007877349853516
eval_loss: 21.987159729003906 psnr: 35.73712921142578
iter 49300, train_loss 20.97229766845703
eval_loss: 23.503881454467773 psnr: 35.44736862182617
iter 49350, train_loss 16.45563507080078
eval_loss: 22.67538070678711 psnr: 35.60525894165039
iter 49400, train_loss 17.926084518432617
eval_loss: 22.090272903442383 psnr: 35.70931625366211
iter 49450, train_loss 19.77572250366211
eval_loss: 22.614234924316406 psnr: 35.64556884765625
iter 49500, train_loss 19.199085235595703
eval_loss: 22.28802490234375 psnr: 35.70840835571289
iter 49550, train_loss 16.824371337890625
eval_loss: 21.28582763671875 psnr: 35.923160552978516
iter 49600, train_loss 16.793943405151367
eval_loss: 22.09378433227539 psnr: 35.759830474853516
iter 49650, train_loss 19.489826202392578
eval_loss: 22.89432144165039 psnr: 35.5599479675293
iter 49700, train_loss 17.30948829650879
eval_loss: 22.109725952148438 psnr: 35.773582458496094
iter 49750, train_loss 19.311826705932617
eval_loss: 21.63386344909668 psnr: 35.78410720825195
iter 49800, train_loss 16.99703025817871
eval_loss: 22.389402389526367 psnr: 35.689876556396484
iter 49850, train_loss 17.83291244506836
eval_loss: 21.214235305786133 psnr: 35.86458206176758
iter 49900, train_loss 16.42654800415039
eval_loss: 22.055845260620117 psnr: 35.707275390625
iter 49950, train_loss 17.106632232666016
eval_loss: 21.848424911499023 psnr: 35.83623504638672
iter 50000, train_loss 19.356897354125977
eval_loss: 21.733983993530273 psnr: 35.79822540283203
test_loss: 21.62784194946289, psnr: 35.829925537109375
